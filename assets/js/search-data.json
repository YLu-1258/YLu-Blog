{
  
    
        "post0": {
            "title": "Summer Recommender System Algo Research",
            "content": "Import all of our required modules . import pandas as pd import numpy as np !pip install scikit-surprise from surprise import Dataset from surprise import Reader import scipy . Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.7/dist-packages (1.1.1) Requirement already satisfied: scipy&gt;=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.4.1) Requirement already satisfied: numpy&gt;=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.19.5) Requirement already satisfied: six&gt;=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.15.0) Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.0.1) . Import and process our data . ## Importing our ratings data ratings = pd.read_csv(&quot;rating.csv&quot;) anime = pd.read_csv(&quot;anime.csv&quot;) ## removing entries with no ratings and resetting indices ratings = ratings.head(125000) ## Apply to_numeric and removing all NaN values ratings = ratings.apply(pd.to_numeric, errors=&#39;coerce&#39;) ratings = ratings.dropna() ## Declaring some stuff for KNN calculation reader = Reader(rating_scale=(1, 10)) data = Dataset.load_from_df(ratings[[&quot;user_id&quot;, &quot;anime_id&quot;, &quot;rating&quot;]], reader) ratings . user_id anime_id rating . 0 1 | 20 | -1 | . 1 1 | 24 | -1 | . 2 1 | 79 | -1 | . 3 1 | 226 | -1 | . 4 1 | 241 | -1 | . ... ... | ... | ... | . 124995 1272 | 4382 | 10 | . 124996 1272 | 4672 | 5 | . 124997 1272 | 4792 | 6 | . 124998 1272 | 4898 | 8 | . 124999 1272 | 4910 | 6 | . 125000 rows × 3 columns . KNN . ratings[[&quot;user_id&quot;, &quot;anime_id&quot;, &quot;rating&quot;]] . user_id anime_id rating . 0 1 | 20 | -1 | . 1 1 | 24 | -1 | . 2 1 | 79 | -1 | . 3 1 | 226 | -1 | . 4 1 | 241 | -1 | . ... ... | ... | ... | . 124995 1272 | 4382 | 10 | . 124996 1272 | 4672 | 5 | . 124997 1272 | 4792 | 6 | . 124998 1272 | 4898 | 8 | . 124999 1272 | 4910 | 6 | . 125000 rows × 3 columns . from surprise import KNNWithMeans sim_options = { &quot;name&quot;: &quot;msd&quot;, &quot;min_support&quot;: 3, &quot;user_based&quot;: False, # Compute similarities between items } algo = KNNWithMeans(sim_options=sim_options) user_id = input(&quot;User Id &gt;&gt;&gt; &quot;) anime_id = input(&quot;Anime Id &gt;&gt;&gt; &quot;) trainingSet = data.build_full_trainset() algo.fit(trainingSet) prediction = algo.predict(int(user_id), int(anime_id)) from google.colab import output output.clear() print(&quot;User {0} would rate anime number {1}&quot;.format(str(user_id), str(anime_id))) prediction.est . User 3 would rate anime number 101 . 6.695240884293928 . from surprise import KNNWithZScore sim_options = { &quot;name&quot;: &quot;msd&quot;, &quot;min_support&quot;: 3, &quot;user_based&quot;: False, # Compute similarities between items } algo = KNNWithZScore(sim_options=sim_options) user_id = input(&quot;User Id &gt;&gt;&gt; &quot;) anime_id = input(&quot;Anime Id &gt;&gt;&gt; &quot;) trainingSet = data.build_full_trainset() algo.fit(trainingSet) prediction = algo.predict(int(user_id), int(anime_id)) from google.colab import output output.clear() print(&quot;User {0} would rate anime number {1}&quot;.format(str(user_id), str(anime_id))) prediction.est . User 3 would rate anime number 101 . 6.702780614370237 . SVD algorithm . Basic algorithms NormalPredictor NormalPredictor algorithm predicts a random rating based on the distribution of the training set, which is assumed to be normal. This is one of the most basic algorithms that do not do much work. BaselineOnly BaselineOnly algorithm predicts the baseline estimate for given user and item. k-NN algorithms KNNBasic KNNBasic is a basic collaborative filtering algorithm. KNNWithMeans KNNWithMeans is basic collaborative filtering algorithm, taking into account the mean ratings of each user. KNNWithZScore KNNWithZScore is a basic collaborative filtering algorithm, taking into account the z-score normalization of each user. KNNBaseline KNNBaseline is a basic collaborative filtering algorithm taking into account a baseline rating. Matrix Factorization-based algorithms SVD SVD algorithm is equivalent to Probabilistic Matrix Factorization SVDpp The SVDpp algorithm is an extension of SVD that takes into account implicit ratings. NMF NMF is a collaborative filtering algorithm based on Non-negative Matrix Factorization. It is very similar with SVD. Slope One SlopeOne is a straightforward implementation of the SlopeOne algorithm. Co-clustering Coclustering is a collaborative filtering algorithm based on co-clustering. We use “rmse” as our accuracy metric for the predictions. . KNNWithMeans . from surprise import KNNWithMeans from surprise import Dataset from surprise.model_selection import GridSearchCV data = Dataset.load_from_df(ratings[[&quot;user_id&quot;, &quot;anime_id&quot;, &quot;rating&quot;]], reader) sim_options = { &quot;name&quot;: [&quot;msd&quot;, &quot;cosine&quot;], &quot;min_support&quot;: [3, 4, 5], &quot;user_based&quot;: [False, True], } param_grid = {&quot;sim_options&quot;: sim_options} gs = GridSearchCV(KNNWithMeans, param_grid, measures=[&quot;rmse&quot;, &quot;mae&quot;], cv=3) gs.fit(data) print(gs.best_score[&quot;rmse&quot;]) print(gs.best_params[&quot;rmse&quot;]) print(gs.best_score[&quot;mae&quot;]) print(gs.best_params[&quot;mae&quot;]) # Cleaned # rmse 1.1961042065214869 # {&#39;sim_options&#39;: {&#39;name&#39;: &#39;msd&#39;, &#39;min_support&#39;: 3, &#39;user_based&#39;: True}} # mae 0.9066350800152176 #{&#39;sim_options&#39;: {&#39;name&#39;: &#39;msd&#39;, &#39;min_support&#39;: 3, &#39;user_based&#39;: False}} # Original #2.300630451838356 #{&#39;sim_options&#39;: {&#39;name&#39;: &#39;msd&#39;, &#39;min_support&#39;: 4, &#39;user_based&#39;: True}} #1.6207772901276576 #{&#39;sim_options&#39;: {&#39;name&#39;: &#39;msd&#39;, &#39;min_support&#39;: 5, &#39;user_based&#39;: True}} # runtime 4m 28s . Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. 2.300630451838356 {&#39;sim_options&#39;: {&#39;name&#39;: &#39;msd&#39;, &#39;min_support&#39;: 4, &#39;user_based&#39;: True}} 1.6207772901276576 {&#39;sim_options&#39;: {&#39;name&#39;: &#39;msd&#39;, &#39;min_support&#39;: 5, &#39;user_based&#39;: True}} . KNNWithZScore . from surprise import KNNWithZScore from surprise import Dataset from surprise.model_selection import GridSearchCV data = Dataset.load_from_df(ratings[[&quot;user_id&quot;, &quot;anime_id&quot;, &quot;rating&quot;]], reader) sim_options = { &quot;name&quot;: [&quot;msd&quot;, &quot;cosine&quot;], &quot;min_support&quot;: [3, 4, 5], &quot;user_based&quot;: [False, True], } param_grid = {&quot;sim_options&quot;: sim_options} gs = GridSearchCV(KNNWithZScore, param_grid, measures=[&quot;rmse&quot;, &quot;mae&quot;], cv=3) gs.fit(data) print(gs.best_score[&quot;rmse&quot;]) print(gs.best_params[&quot;rmse&quot;]) print(gs.best_score[&quot;mae&quot;]) print(gs.best_params[&quot;mae&quot;]) # Cleaned #rmse 1.2200524149502934 #{&#39;sim_options&#39;: {&#39;name&#39;: &#39;msd&#39;, &#39;min_support&#39;: 3, &#39;user_based&#39;: True}} #mae 0.9071607750307225 #{&#39;sim_options&#39;: {&#39;name&#39;: &#39;msd&#39;, &#39;min_support&#39;: 4, &#39;user_based&#39;: True}} # Original #2.3157416009374785 #{&#39;sim_options&#39;: {&#39;name&#39;: &#39;cosine&#39;, &#39;min_support&#39;: 4, &#39;user_based&#39;: True}} #1.608562753271584 #{&#39;sim_options&#39;: {&#39;name&#39;: &#39;cosine&#39;, &#39;min_support&#39;: 4, &#39;user_based&#39;: True}} #runtime 9m 28s . Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. Computing the cosine similarity matrix... Done computing similarity matrix. 2.3157416009374785 {&#39;sim_options&#39;: {&#39;name&#39;: &#39;cosine&#39;, &#39;min_support&#39;: 4, &#39;user_based&#39;: True}} 1.608562753271584 {&#39;sim_options&#39;: {&#39;name&#39;: &#39;cosine&#39;, &#39;min_support&#39;: 4, &#39;user_based&#39;: True}} . BaselineOnly . from surprise import BaselineOnly from surprise import Dataset from surprise.model_selection import GridSearchCV # Misc data = Dataset.load_from_df(ratings[[&quot;user_id&quot;, &quot;anime_id&quot;, &quot;rating&quot;]], reader) bsl_options = {&#39;method&#39;: [&#39;als&#39;, &#39;sgd&#39;], &#39;n_epochs&#39;: [1,5,10], &#39;reg_u&#39;: [12], &#39;reg_i&#39;: [5] } param_grid = {&quot;bsl_options&quot;: bsl_options} gs = GridSearchCV(BaselineOnly, param_grid, measures=[&quot;rmse&quot;, &quot;mae&quot;], cv=3) gs.fit(data) print(gs.best_score[&quot;rmse&quot;]) print(gs.best_params[&quot;rmse&quot;]) print(gs.best_score[&quot;mae&quot;]) print(gs.best_params[&quot;mae&quot;]) # Original # rmse 1.1937039196145423 #{&#39;bsl_options&#39;: {&#39;method&#39;: &#39;als&#39;, &#39;n_epochs&#39;: 10, &#39;reg_u&#39;: 12, &#39;reg_i&#39;: 5}} # mae 0.9073417853583354 #{&#39;bsl_options&#39;: {&#39;method&#39;: &#39;als&#39;, &#39;n_epochs&#39;: 10, &#39;reg_u&#39;: 12, &#39;reg_i&#39;: 5}} # Cleaned #2.2457828423033965 #{&#39;bsl_options&#39;: {&#39;method&#39;: &#39;sgd&#39;, &#39;n_epochs&#39;: 10, &#39;reg_u&#39;: 12, &#39;reg_i&#39;: 5}} #1.6065790249351644 #{&#39;bsl_options&#39;: {&#39;method&#39;: &#39;sgd&#39;, &#39;n_epochs&#39;: 10, &#39;reg_u&#39;: 12, &#39;reg_i&#39;: 5}} # runtime 12s . Estimating biases using als... Estimating biases using als... Estimating biases using als... Estimating biases using als... Estimating biases using als... Estimating biases using als... Estimating biases using als... Estimating biases using als... Estimating biases using als... Estimating biases using sgd... Estimating biases using sgd... Estimating biases using sgd... Estimating biases using sgd... Estimating biases using sgd... Estimating biases using sgd... Estimating biases using sgd... Estimating biases using sgd... Estimating biases using sgd... 2.2457828423033965 {&#39;bsl_options&#39;: {&#39;method&#39;: &#39;sgd&#39;, &#39;n_epochs&#39;: 10, &#39;reg_u&#39;: 12, &#39;reg_i&#39;: 5}} 1.6065790249351644 {&#39;bsl_options&#39;: {&#39;method&#39;: &#39;sgd&#39;, &#39;n_epochs&#39;: 10, &#39;reg_u&#39;: 12, &#39;reg_i&#39;: 5}} . SVD . from surprise import SVD from surprise import Dataset from surprise.model_selection import GridSearchCV # Matrix facotization sim_options = { &quot;n_epochs&quot;: [5,10], &quot;lr_all&quot;: [0.002, 0.005], &quot;reg_all&quot;: [0.4,0.6] } gs = GridSearchCV(SVD, sim_options, measures=[&quot;rmse&quot;, &quot;mae&quot;], cv=3) gs.fit(data) print(gs.best_score[&quot;rmse&quot;]) print(gs.best_params[&quot;rmse&quot;]) print(gs.best_score[&quot;mae&quot;]) print(gs.best_params[&quot;mae&quot;]) # Original #rmse 1.2370006802584665 #{&#39;n_epochs&#39;: 10, &#39;lr_all&#39;: 0.005, &#39;reg_all&#39;: 0.4} #mae 0.9457554878434046 #{&#39;n_epochs&#39;: 10, &#39;lr_all&#39;: 0.005, &#39;reg_all&#39;: 0.4} # Cleaned #2.3105571863770495 #{&#39;n_epochs&#39;: 10, &#39;lr_all&#39;: 0.005, &#39;reg_all&#39;: 0.4} #1.7100669607848105 #{&#39;n_epochs&#39;: 10, &#39;lr_all&#39;: 0.005, &#39;reg_all&#39;: 0.4} #runtime 1m 44s . 2.3105571863770495 {&#39;n_epochs&#39;: 10, &#39;lr_all&#39;: 0.005, &#39;reg_all&#39;: 0.4} 1.7100669607848105 {&#39;n_epochs&#39;: 10, &#39;lr_all&#39;: 0.005, &#39;reg_all&#39;: 0.4} . KNNBasic . from surprise import KNNBasic from surprise import Dataset from surprise.model_selection import GridSearchCV # Clustering sim_options = { &quot;name&quot;: [&quot;msd&quot;, &quot;cosine&quot;], &quot;k&quot;: [20,40], &quot;min_k&quot;: [5, 7], &quot;verbose&quot;: [True] } gs = GridSearchCV(KNNBasic, sim_options, measures=[&quot;rmse&quot;, &quot;mae&quot;], cv=3) gs.fit(data) print(gs.best_score[&quot;rmse&quot;]) print(gs.best_params[&quot;rmse&quot;]) print(gs.best_score[&quot;mae&quot;]) print(gs.best_params[&quot;mae&quot;]) # Cleaned #rmse 1.3169600252251181 #{&#39;name&#39;: &#39;msd&#39;, &#39;k&#39;: 20, &#39;min_k&#39;: 5, &#39;verbose&#39;: True} #mae 0.9971319510312137 #{&#39;name&#39;: &#39;msd&#39;, &#39;k&#39;: 20, &#39;min_k&#39;: 5, &#39;verbose&#39;: True} # Original #2.61306062703497 #{&#39;name&#39;: &#39;msd&#39;, &#39;k&#39;: 20, &#39;min_k&#39;: 5, &#39;verbose&#39;: True} #1.7634939088675168 #{&#39;name&#39;: &#39;msd&#39;, &#39;k&#39;: 20, &#39;min_k&#39;: 5, &#39;verbose&#39;: True} # 4m 53 s . Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. Computing the msd similarity matrix... Done computing similarity matrix. 2.61306062703497 {&#39;name&#39;: &#39;msd&#39;, &#39;k&#39;: 20, &#39;min_k&#39;: 5, &#39;verbose&#39;: True} 1.7634939088675168 {&#39;name&#39;: &#39;msd&#39;, &#39;k&#39;: 20, &#39;min_k&#39;: 5, &#39;verbose&#39;: True} . NMF . from surprise import NMF from surprise import Dataset from surprise.model_selection import GridSearchCV # Matrix Factorization sim_options = { &quot;n_epochs&quot;: [5,10,15,20], &quot;biased&quot;: [True,False], &quot;reg_pu&quot;: [0.01, 0.06, 0.5, 1], &quot;reg_qi&quot;: [0.01, 0.06, 0.5, 1], &quot;verbose&quot;: [True] } gs = GridSearchCV(NMF, sim_options, measures=[&quot;rmse&quot;, &quot;mae&quot;], cv=3) gs.fit(data) print(gs.best_score[&quot;rmse&quot;]) print(gs.best_params[&quot;rmse&quot;]) print(gs.best_score[&quot;mae&quot;]) print(gs.best_params[&quot;mae&quot;]) # Cleaned #1.1889671285702674 #{&#39;n_epochs&#39;: 20, &#39;biased&#39;: True, &#39;reg_pu&#39;: 0.01, &#39;reg_qi&#39;: 1, &#39;verbose&#39;: True} #0.9011699311141764 #{&#39;n_epochs&#39;: 20, &#39;biased&#39;: True, &#39;reg_pu&#39;: 0.01, &#39;reg_qi&#39;: 1, &#39;verbose&#39;: True} # Original #2.2452077636572434 #{&#39;n_epochs&#39;: 10, &#39;biased&#39;: True, &#39;reg_pu&#39;: 0.5, &#39;reg_qi&#39;: 0.5, &#39;verbose&#39;: True} #1.6074999998727018 #{&#39;n_epochs&#39;: 20, &#39;biased&#39;: True, &#39;reg_pu&#39;: 1, &#39;reg_qi&#39;: 1, &#39;verbose&#39;: True} #runtime 11m 25s . Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 2.2452077636572434 {&#39;n_epochs&#39;: 10, &#39;biased&#39;: True, &#39;reg_pu&#39;: 0.5, &#39;reg_qi&#39;: 0.5, &#39;verbose&#39;: True} 1.6074999998727018 {&#39;n_epochs&#39;: 20, &#39;biased&#39;: True, &#39;reg_pu&#39;: 1, &#39;reg_qi&#39;: 1, &#39;verbose&#39;: True} . Normal Predictor . from surprise import NormalPredictor from surprise import Dataset from surprise.model_selection import GridSearchCV # Misc sim_options = { } gs = GridSearchCV(NormalPredictor, sim_options, measures=[&quot;rmse&quot;, &quot;mae&quot;], cv=3) gs.fit(data) print(gs.best_score[&quot;rmse&quot;]) print(gs.best_params[&quot;rmse&quot;]) print(gs.best_score[&quot;mae&quot;]) print(gs.best_params[&quot;mae&quot;]) # Cleaned #rmse 2.0923401858242667 # {} #mae 1.6582413347539269 # {} # Original #4.876980925979471 #{} #3.9231832724710536 #{} #runtime 2s . 4.876980925979471 {} 3.9231832724710536 {} . SlopeOne . from surprise import SlopeOne from surprise import Dataset from surprise.model_selection import GridSearchCV # Clustering param_grid = { } gs = GridSearchCV(SlopeOne, param_grid, measures=[&quot;rmse&quot;, &quot;mae&quot;], cv=3) gs.fit(data) print(gs.best_score[&quot;rmse&quot;]) print(gs.best_params[&quot;rmse&quot;]) print(gs.best_score[&quot;mae&quot;]) print(gs.best_params[&quot;mae&quot;]) # Cleaned #1.2261258397066668 #{} #0.9248136286120494 #{} # Original #2.3148602570198133 #{} #1.646961825093937 #{} #runtime 22s . 2.3148602570198133 {} 1.646961825093937 {} . CoClustering . from surprise import CoClustering from surprise import Dataset from surprise.model_selection import GridSearchCV # Clustering sim_options = { &quot;n_cltr_u&quot;: [2,3,4], &quot;n_cltr_i&quot;: [2,3,4], &quot;n_epochs&quot;: [10,15,20], &quot;verbose&quot; : [True] } gs = GridSearchCV(CoClustering, sim_options, measures=[&quot;rmse&quot;, &quot;mae&quot;], cv=3) gs.fit(data) print(gs.best_score[&quot;rmse&quot;]) print(gs.best_params[&quot;rmse&quot;]) print(gs.best_score[&quot;mae&quot;]) print(gs.best_params[&quot;mae&quot;]) # Cleaned #1.2533606254732572 #{&#39;n_cltr_u&#39;: 4, &#39;n_cltr_i&#39;: 2, &#39;n_epochs&#39;: 10, &#39;verbose&#39;: True} #0.9453075653296411 #{&#39;n_cltr_u&#39;: 4, &#39;n_cltr_i&#39;: 2, &#39;n_epochs&#39;: 10, &#39;verbose&#39;: True} # Original #2.3921675151385458 #{&#39;n_cltr_u&#39;: 3, &#39;n_cltr_i&#39;: 2, &#39;n_epochs&#39;: 20, &#39;verbose&#39;: True} #1.687391909272779 #{&#39;n_cltr_u&#39;: 4, &#39;n_cltr_i&#39;: 2, &#39;n_epochs&#39;: 15, &#39;verbose&#39;: True} #runtime 10m 37s . Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 Processing epoch 0 Processing epoch 1 Processing epoch 2 Processing epoch 3 Processing epoch 4 Processing epoch 5 Processing epoch 6 Processing epoch 7 Processing epoch 8 Processing epoch 9 Processing epoch 10 Processing epoch 11 Processing epoch 12 Processing epoch 13 Processing epoch 14 Processing epoch 15 Processing epoch 16 Processing epoch 17 Processing epoch 18 Processing epoch 19 2.3921675151385458 {&#39;n_cltr_u&#39;: 3, &#39;n_cltr_i&#39;: 2, &#39;n_epochs&#39;: 20, &#39;verbose&#39;: True} 1.687391909272779 {&#39;n_cltr_u&#39;: 4, &#39;n_cltr_i&#39;: 2, &#39;n_epochs&#39;: 15, &#39;verbose&#39;: True} . KNNBaseline . # Clustering from surprise import KNNBaseline from surprise import Dataset from surprise.model_selection import GridSearchCV data = Dataset.load_from_df(ratings[[&quot;user_id&quot;, &quot;anime_id&quot;, &quot;rating&quot;]], reader) sim_options = { &quot;name&quot;: [&quot;msd&quot;, &quot;cosine&quot;], &quot;min_support&quot;: [3, 4, 5], &quot;user_based&quot;: [False, True], } param_grid = {&quot;sim_options&quot;: sim_options} gs = GridSearchCV(KNNBaseline, param_grid, measures=[&quot;rmse&quot;, &quot;mae&quot;], cv=3) gs.fit(data) print(gs.best_score[&quot;rmse&quot;]) print(gs.best_params[&quot;rmse&quot;]) print(gs.best_score[&quot;mae&quot;]) print(gs.best_params[&quot;mae&quot;]) # Cleaned #1.1832580437001543 #{&#39;sim_options&#39;: {&#39;name&#39;: &#39;msd&#39;, &#39;min_support&#39;: 5, &#39;user_based&#39;: False}} #0.8893399468276982 #{&#39;sim_options&#39;: {&#39;name&#39;: &#39;msd&#39;, &#39;min_support&#39;: 5, &#39;user_based&#39;: False}} # Original #2.2179062356553265 #{&#39;sim_options&#39;: {&#39;name&#39;: &#39;msd&#39;, &#39;min_support&#39;: 5, &#39;user_based&#39;: False}} #1.54544242417866 #{&#39;sim_options&#39;: {&#39;name&#39;: &#39;msd&#39;, &#39;min_support&#39;: 5, &#39;user_based&#39;: False}} #runtime 5m 15s . Estimating biases using als... Computing the msd similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the msd similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the msd similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the msd similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the msd similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the msd similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the msd similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the msd similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the msd similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the msd similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the msd similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the msd similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the msd similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the msd similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the msd similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the msd similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the msd similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the msd similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the cosine similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the cosine similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the cosine similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the cosine similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the cosine similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the cosine similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the cosine similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the cosine similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the cosine similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the cosine similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the cosine similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the cosine similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the cosine similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the cosine similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the cosine similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the cosine similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the cosine similarity matrix... Done computing similarity matrix. Estimating biases using als... Computing the cosine similarity matrix... Done computing similarity matrix. 2.2179062356553265 {&#39;sim_options&#39;: {&#39;name&#39;: &#39;msd&#39;, &#39;min_support&#39;: 5, &#39;user_based&#39;: False}} 1.54544242417866 {&#39;sim_options&#39;: {&#39;name&#39;: &#39;msd&#39;, &#39;min_support&#39;: 5, &#39;user_based&#39;: False}} . SVDpp . # Matrix facotrization from surprise import SVDpp from surprise import Dataset from surprise.model_selection import GridSearchCV data = Dataset.load_from_df(ratings[[&quot;user_id&quot;, &quot;anime_id&quot;, &quot;rating&quot;]], reader) param_grid = { &quot;n_epochs&quot;: [5,10], &quot;lr_all&quot;: [0.002, 0.005], &quot;reg_all&quot;: [0.4,0.6] } gs = GridSearchCV(SVDpp, param_grid, measures=[&quot;rmse&quot;, &quot;mae&quot;], cv=3) gs.fit(data) print(gs.best_score[&quot;rmse&quot;]) print(gs.best_params[&quot;rmse&quot;]) print(gs.best_score[&quot;mae&quot;]) print(gs.best_params[&quot;mae&quot;]) # Cleaned #1.236439713814388 #{&#39;n_epochs&#39;: 10, &#39;lr_all&#39;: 0.005, &#39;reg_all&#39;: 0.4} #0.9482547980069017 #{&#39;n_epochs&#39;: 10, &#39;lr_all&#39;: 0.005, &#39;reg_all&#39;: 0.4} # Original #2.30757862188976 #{&#39;n_epochs&#39;: 10, &#39;lr_all&#39;: 0.005, &#39;reg_all&#39;: 0.4} #1.6811210573467745 #{&#39;n_epochs&#39;: 10, &#39;lr_all&#39;: 0.005, &#39;reg_all&#39;: 0.4} #runtime 27m 43s . 2.30757862188976 {&#39;n_epochs&#39;: 10, &#39;lr_all&#39;: 0.005, &#39;reg_all&#39;: 0.4} 1.6811210573467745 {&#39;n_epochs&#39;: 10, &#39;lr_all&#39;: 0.005, &#39;reg_all&#39;: 0.4} .",
            "url": "https://ylu-1258.github.io/YLu-Blog/jupyter/interests/2022/08/29/Summer-Research-ML-results.html",
            "relUrl": "/jupyter/interests/2022/08/29/Summer-Research-ML-results.html",
            "date": " • Aug 29, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "An Empirical Study On Performance Measures Of Collaborative Filtering Recommendation Algorithms",
            "content": "An Empirical Study on Performance Measures of Collaborative Filtering Recommendation Algorithms . Alex Lu . maodou1258@gmail.com . Abstract . In recent times, recommendation engines have become increasingly popular within many industries. The focus of such an engine is to implement an algorithm to successfully make recommendations based on user preferences. Because of the utility provided by such tools, many industries heavily rely on such engines to provide accurate product recommendations to customers. Some popular algorithms implemented include clustering, matrix factorization, and deep learning implementations. Such algorithms are utilized within Collaborative Filtering methods and are simulated using pre-made datasets containing user and item information. Performance metrics are then applied to the algorithm to test the accuracy of the model. Results show that deep learning algorithms provide greater . performance when compared to other applications. . Keywords - Collaborative filtering, RMSE, Deep Learning, MAE, matrix factorization, Performance Measure . 1. Introduction . Latterly, recommendation engines serve a great purpose in many online services and enhance the consumer experience by providing lists of recommended items to users. Many big corporations such as Netflix, Amazon, Youtube, and others provide item recommendations through such methods to promote the sales and usage of their goods. The general idea of a recommender system is to return a list of items that the user would find interesting. Implementing various different types of engines provides insight towards which algorithm is the most suitable for certain scenarios. . Different approaches by different algorithms could have varying performances depending on the type of recommendation required, and the core nature of the dataset used. This research is primarily conducted on collaborative-filtering techniques, but similar research could be conducted on content-based implementations. Examples of potential implementations could be clustering and matrix factorization approaches. The main accuracy metrics utilized in the research are the RMSE and MAE metrics which are further explained later in the paper. . Two main research questions would serve as the focus of the research. More conclusions could be drawn from the data collected, but the main aim of the research are as follows: . I) What CF implementation provides the accuracy measure for a standard data set containing user, item and rating information? II) How does data sparsity affect the prediction accuracy of the models implemented? . 2. Background . Recommendation engines are programs used to provide item recommendations to users based on filtering each item and returning a . possible predicted rating for the user. The two main implementations of recommendation engines are content-based filtering and collaborative filtering. . 2.1 Content-based Filtering . A content-based filtering engine takes into account the user’s own item history and focuses on keywords in items rather than similarity between users [1]. However, such implementation can lead to a scenario where providing a broad range of recommendations would become impossible. Because of the nature of content-based filtering engines, items that were utilized by similar users wouldn’t be recommended to the main user purely because of the lack of a keyword or phrase. A dataset for such an engine would incorporate items along with a detailed profile for each item. . Despite its narrower scope when providing recommendations, content-based filtering systems often reduce the amount of data needed to make accurate predictions. For collaborative filtering, a greater range of data is required for a proper calculation of an item. To put it simply, the more data the engine has, the more . accurate the prediction is. However, with the nature of content-based filtering, any amount of data would suffice, providing that there are items that match the recommendation requirements. . 2.2 Collaborative Filtering . A collaborative filtering engine takes into account other user’s ratings, and returns . algorithms. This paper would primarily focus on model-based algorithms and approaches. The similarity between users could be found in various methods. For this study, a total of twelve algorithms were implemented. The main focus was placed on nearest neighbors, matrix factorization, and deep learning algorithms. Figure 2.1 maps out the various . . recommendations based on similarity. Collaborative filtering is split into two main approaches, model-based and memory based . algorithms implemented in this research. 2.3 Nearest Neighbor . Nearest neighbor, or more specifically, k nearest neighbors is a collaborative filtering . algorithm used to find similarities between items and users based on the total distance between two neighbors [2]. A weight system could also be applied so that a neighbor closer to the main user would have more weight on the recommendations than one who is further away. . Four of the twelve algorithms used in the research were from this category. KNNBasic, KNNWithZScore, KNNWithMeans, and KNNBaseline were such implementations of this category of algorithms. . 2.4 Matrix Factorization . Matrix Factorization is yet again another implementation of collaborative filtering. Simply put, a matrix factorization relates two separate values together under a specific value to create a grid or matrix of the data [3]. However, as data is not evenly distributed, some cells in the matrix are left empty and would need to be filled in to provide recommendations. Such values are known as “latent features”. . Some matrix factorizations implemented in the research were Negative Matrix Factorization, Singular Value Decomposition, and SVD++. . 2.5 Deep Learning . A deep learning model utilizes a neural network to process and calculate information. Much like a human brain, deep learning attempts to make predictions based on data much like a human brain. . The deep learning model implemented in this experiment utilizes an embedding layer structure [4]. Using such a structure could organize data into a vector of discrete values which could then produce similarity results and tests through the distance between vectors. These types of embedding layers could be generated through frameworks such as “Pytorch” or “Tensorflow”, however, this research would be implemented in Pytorch. The model could then be trained through a series of epochs and eventually provide predictions. . 2.6 Miscellaneous surprise algorithms . The miscellaneous category comprises the leftover algorithms in the surprise package that do not fit into any of the other categories in the research. Such algorithms were as listed: Co . Clustering, Normal Predictor, Baseline-Only, and Slope-One. . According to Sahar Karat Co-Clustering is a collaborative filtering algorithm used to provide recommendations by “A simultaneous clustering of the rows and columns of a matrix” [5]. Classical clustering algorithms only focus on one specific type of data, while co . clustering could be used to accommodate two simultaneously. . Normal predictor is an algorithm provided by the surprise package that provides random user recommendations based on the data distribution in the dataset. The “Maximum Likelihood Estimation” method is utilized in this calculation. . Baseline-Only is yet another surprise algorithm that makes baseline predictions based on the data provided. There are two main ways to implement this algorithm. The first implementation method is “Stochastic Gradient . Descent” (SGD), which calculates a gradient of the dataset by a random selection of data. The other implementation is to use “Alternating Least Squares” (ALS) which is a matrix factorization algorithm that works well with sparser sets of data. . Slope-One is an example of an item-based collaborative filtering recommendation algorithm. Predictions made with this model are generally based on personal ratings as well as similar community ratings. . Further information and implementations on the methods listed could be found on the surprise documentations [6]. . 2.7 Accuracy Metrics . Two accuracy metrics were used in the process of this research. Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) [11]. . RMSE is a quadratic model that assigns much larger weights to larger errors observed. Accuracy is calculated through RMSE by taking the square root of the mean of the sum of the squared difference of each predicted . value and its corresponding actual value. The formula is displayed in Figure 2.2 . . (Figure 2.2) . MAE is a linear metric model that linearly scales error. This model is typically used when higher errors are not important to the observation. Accuracy is calculated through MAE by taking the mean of the sum of the absolute values of the differences between the predicted and actual values. The formula is displayed in Figure 2.3 . . (Figure 2.3) . 3. Related Work . Various research topics have already been analyzed in the field of collaborative filtering. A few similar pieces of research provide similar methods and implementations. A plethora of CF models has been implemented and researched. . 3.1 Similar Research . Similar research was conducted by Mojdeh Saadati et al. [7] on the implementations of various models on movie recommender systems. The two models used in the experiment were the matrix factorization model SVD and a deep learning implementation of the Restricted Boltzmann Machine. The performance of the implementations was measured in the RMSE metric. However, in this research, we go over a broader spectrum of algorithms from each group of implementations and produce results for a larger picture between the different implementations. . 3.2 Further Research . He et al. [8] Conducted Research on how Matrix Factorization could be implemented with Deep Learning to create a better performing model for collaborative filtering. The proposed idea was to use two main models, the Generalized Matrix Factorization (GMF), and the Multi-Layer Perceptron (MLP) to create a hybrid between deep learning and matrix factorization implementations to create a new neural matrix factorization model . dubbed “NeuMF”. NeuMf was then compared to other well-known models such as KNN and ALS implementations and proved to have better accuracy and less training loss. . Yedder et al. [9] Researched the performance of the restricted Boltzmann machine. Various hidden units, learning rates, and other factors were incorporated into the research. Problems such as data sparsity were also encountered in the research and required other methods of implementation. This research also utilized the RMSE accuracy metric to rate the performance of the model. The research indicated an excellent RMSE measure of 0.46. . 4. Approach . This study was broken up into three parts, cleaning, implementation, and evaluation. We will first check for invalid values throughout the dataset, then begin to implement algorithms, and finally calculate performance values. . 4.1 Dataset . The data that would be primarily used in this study is the Kaggle dataset “Anime . Recommendations Database” [10] based on the data collected from myanimelist.net and is included in the reference section of the study. The two files contained within the database are the “ratings.csv” and “anime.csv”. The research would mostly work with the ratings file, but the anime dataset could be further implemented in future research incorporating variables such as show genre and overall ratings. The anime dataset is separated into three separate columns. The user_id, anime_id, and ratings columns are provided for analyzing similarities between users. The format and example of the file are illustrated in Figure 4.1. . (Figure 4.1) . The python module “pandas” was used to import the data into a data frame which could . then be cleaned and analyzed. Making a copy of the dataset to work on is recommended. Maintaining two different data frames would help compare the results on the original to the results in the cleaned dataset. . The first thing to take note of while cleaning is to remove all rows with a rating of “-1”. Such rows represent user data that does not have a specified rating for the specific show that they watched. This step is crucial as having such data in the project would result in a sparse dataset, which directly decreases performance as shown later in the results. A total of 7.8 million rows of data were in the dataset, after cleaning, about 6.3 million rows remained. The distribution of this data is shown in figure 4.2. . . (Figure 4.2) . Another issue arose again while trying to apply the dataset to our engine. Certain cells in . our dataset possibly had ‘NaN’ values, which would in turn cause an error in actual predictions where a value of ‘NaN’ would be returned instead of an integer of the predicted rating. To resolve this issue, we first applied the ‘to_numeric’ method from the pandas module to convert each value into workable integer or float values. After, we could then finally lower the runtime of our experiment by decreasing the size of our dataset from 6 million down to 125,000. This number was picked for easier splitting while implementing other algorithms and deep learning which require testing and training datasets. From there, we then calculated the distribution of the ratings by counting the number of each rating in our dataset. After clearing, it’s paramount to re index the rows in the data frame. Removing the invalid A distribution of the ratings is demonstrated in Figure 4.3. . . (Figure 4.3) . A correlation heatmap could also be used to detect any possible correlations between the values given, however, as of now, there is no apparent relation. . . (Figure 4.4) . 4.2 Implementation . The python package scikit-surprise contains most of the algorithms implemented in this research. First and foremost, we must declare a rating scale for our dataset by utilizing the reader class, and also initializing our dataset with the Dataset class. We set a new . “ratings“ object over the range of one to ten, which is represented in our data. Using the three columns from our pandas data frame, we could then load the data into surprise using the Dataset.load_from_df() method. . After the data is loaded, we could then specify a “param_list” dictionary. In the dictionary, the name of the specific parameters would be stored as the keys and the possible values as a list in the values. Further explanation of what specific params do for each algorithm is also provided in the surprise documentation. . The param_list dictionary could then be imputed into the GridSearchCV() method along with the algorithm name, performance measures, and a cross-validation iterator of 3. There are other arguments as well, but for the sake of our research, these four should be enough. The final step is to then fit our premade data with our GridSearchCV method with the .fit() function. Once everything is set up, the accuracy metrics could then just be retrieved via the best_score iterator. . The deep learning algorithm specifically was generated using an embedding layer with . dropout layers. The entire network consists of 4 total layers. After setting up the net, we can begin to train our model and loop over varying amounts of epochs to find the accuracy that is desired. . To determine the RMSE and the MAE values of this approach, we could separate our dataset into predictions and truth arrays. We can then apply the formulas for both RMSE and MAE as shown in Figures 2.2 and 2.3. We can implement these metrics in two ways. The first method is to use a NumPy array to subject each vector of values from each other and then to apply the formula to our newly generated values. Our second approach is more basic and rudimentary. We could subtract each truth value from each prediction value in our function by declaring a function and then apply the formula to our sum. . 5. Results . In this research, two sets of results were collected. The data collected on the cleaned dataset would serve to be our solution to the first question. However, the data collected on the original dataset would be utilized to answer . the second question concerning the performance measures on sparse datasets. 5.1 Cleaned Dataset . We have gathered both RMSE and MAE values for each algorithm used on our cleaned dataset from our implementations. In the first part of this experiment, the data set has already been cleaned of any invalid values and has reduced sparsity. The majority of the algorithms implemented all showed similar results except a couple of outliers and certain points. A table of the data collected is shown in Figure 5.1 . . (Figure 5.1) . Using the RMSE as the x-axis and MAE for the y-axis, we can plot a scatter plot of our data (Figure 5.2). . . (Figure 5.2) . Removing the Normal Predictor outlier value provides us with a clearer image of the differences in the lower valued points (Figure 5.3). . . (Figure 5.3) . Our data shows that the worst-performing algorithm that we had implemented was the Normal Predictor algorithm from the surprise package, while the best-performing implementation was the Deep Learning algorithm based on neural networks. . 5.1 Pre-cleaned Dataset . Loading up a new dataset, we can effectively run all our algorithms again while maintaining the sparsity of the original dataset. The only cleaning that had to be done was to remove all NaN values and also convert all data to numeric values. The results of running the . implementations on the sparser dataset are recorded in the figure below (Figure 4.5) . . (Figure 5.4) . The results of the various algorithms on this sparse dataset were also plotted on a scatter plot as shown below in Figure 5.5. . . (Figure 5.5) . Once again, removing the normal predictor outlier gives a clearer representation of our other data points (Figure 5.6). . . (Figure 5.6) . Although the values have increased by a considerable amount in the sparse dataset, the common trend remains between the various data points, and no changes are observed in the best and worst algorithms. Comparing the . results of the cleaned and original data sets, a clear difference could be observed in the RMSE and MAE measures (Figures 5.7-8) . (Figure 5.7) . (Figure 5.8) . 6. Discussion . After analyzing the data collected from the research, the deep learning algorithm and the KNNBaseline implementations were observed to be the best performing with the least error observed with both RMSE and MAE metrics. . A possible reason for the results could be the usage of randomness in the calculation of the Normal Predictor algorithm. The deep learning algorithm may have performed the best because of the various training cycles allocated to it which helped to create a more accurate model after each iteration. Vice versa, the opposite could also be applied to the two worst performing algorithms KNNBasic and Normal Predictor. Such implementations . had basic calculations and weren’t able to take into account outliers and other potential biases in the data. . There was an attempt in the research to implement a Restricted Boltzmann Machine (RBM) model, however, the implementation gave varying results and was difficult to judge the extra ratings of the implementation. This . research could be further pursued in the future with the addition of more deep learning implementations and a narrower focus on the subject of deep learning as a whole. From the results acquired, deep learning has been shown to have improved results compared to other algorithms. Focused research on deep learning implementations would provide the reasoning behind deep learning accuracy. . 7. Conclusion . In this research, we explored various machine learning algorithms, K-Nearest neighbors, Matrix Factorization, Deep learning, etc. Several approaches were implemented from the categories mentioned then tested for accuracy measures. . In both the cleaned and original datasets, the deep learning implementation was shown to the least margin of error when making recommendations. From this, it could be deduced that deep learning is a viable method for collaborative filtering engines working with user, item and rating data. Although different sets of data have varying optimal algorithms, . deep learning was still shown to be extremely accurate compared to other tested algorithms. Analyzing the data collected from the sparse dataset, we can conclude that a sparser set of data would result in less accurate recommendations, sometimes up to double the margin of error observed. Because of this observation, it can be concluded that collaborative filtering best performs with dense datasets. . References . [1] Kirzhner, Elena. “Machine Learning. Explanation of Collaborative . Filtering vs Content Based . Filtering.” Medium, Codeburst, 11 . May 2018, codeburst.io/explanation of-recommender-systems-in . information-retrieval-13077e1d916c. [2] Harrison, Onel. “Machine Learning Basics with the K-Nearest Neighbors Algorithm.” Medium, Towards Data Science, 14 July 2019, . towardsdatascience.com/machine . learning-basics-with-the-k-nearest . neighbors-algorithm-6a6e71d01761. . [3] Chen, Denise. “Recommendation System - Matrix Factorization.” . Medium, Towards Data Science, 9 . July 2020, . towardsdatascience.com/recommend ation-system-matrix-factorization . d61978660b4b. . [4] Sivanantham, Balavivek. . “Recommendation System Implementation With Deep Learning and PyTorch.” Medium, The Startup, 18 Aug. 2020, . medium.com/swlh/recommendation system-implementation-with-deep learning-and-pytorch-a03ee84a96f4. . [5] Karat, Sahar. “Co . Clustering.” Data Science . Made Simpler, 5 Mar. 2016, datasciencemadesimpler.wor dpress.com/tag/co . clustering/. . [6] Hug, Nicholas. “Welcome to Surprise’ Documentation.” Welcome to Surprise’ . Documentation! - Surprise 1 Documentation, 2015, . surprise.readthedocs.io/en/sta ble/. . [7] Mojdeh Saadati, Syed Shihab, Mohammed Shaiqur Rahman “Movie Recommender Systems: Implementation and Performance . Evaluation.” Semantic Scholar, 2019, . www.semanticscholar.org/paper/Mo vie-Recommender-Systems%3A Implementation-and-Saadati Shihab/01470f39285213e53f365ce0 1417b18d12467563#citing-papers. . [8] Xiangnan, He, et al. “Neural Collaborative Filtering.” . International World Wide Web Conference Committee, 3 Apr. 2017. . [9] Yedder, Hanene Ben, et al. “Modeling Prediction in . Recommender Systems Using Restricted Boltzmann Machine.” . IEEE Explore, IEEE, 5 Oct. 2017, ieeexplore.ieee.org/abstract/documen t/8122923. . [10] CooperUnion. “Anime . Recommendations Database.” . Kaggle, Kaggle, 21 Dec. 2016, . www.kaggle.com/CooperUnion/ani me-recommendations-database. . [11] Kampakis, Stylianos. “Performance Measures: RMSE and MAE.” The Data Scientist, The Data Scientist, 26 Nov. 2020, . thedatascientist.com/performance measures-rmse-mae/. .",
            "url": "https://ylu-1258.github.io/YLu-Blog/2022/08/28/An-Empirical-Study-on-Performance-Measures-of-Collaborative-Filtering-Recommendation-Algorithms.html",
            "relUrl": "/2022/08/28/An-Empirical-Study-on-Performance-Measures-of-Collaborative-Filtering-Recommendation-Algorithms.html",
            "date": " • Aug 28, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Alex Lu   Lab #1_ Measurements And Graphical Analysis",
            "content": "Lab #1: Measurements and Graphical Analysis . Alex Lu . Purpose: . Given disks of different radii, determine the relationship between the mass and the radius of the disks through graphical method and calculate the uncertainty associated with the measured value. We will learn about linearization and use it to create a mathematical model. . Materials and Equipment: . Balance . Meter stick . Circular disks (identical thickness and uniform density but different radii) . Graphic Calculator or online graphing tool . Procedure: . Substitute equations to get a relationship between mass and radius. . | Use the relationship between mass and radius to determine what variable should be processed to linearize the data . | Measure the radius (in cm) of the cylinder with the ruler with one end of the ruler at the center of the disk and the other on the edge. . | Zero out the balance and then measure the mass (in grams) of the cylinder. . | Stack the metal cylinders and measure the collective height of all cylinders. Divide by the total number of cylinders multiplied by 2 to the power of the number of folds to find the height of each individual cylinder. . | Organize the collected data into a data table . | Plot the original radius and mass . | Plot the processed radius and mass . | Plug height and other constants to create a relationship between mass and radius. . | Equations and calculations: . Let: . ( rho) be density . | (m) be mass . | (v) be volume . | (a) be the surface area of the cylinder . | (r) be the radii of the cylinder . | (h) be the height of the cylinder . | . Thus: . If ( rho = frac{m}{v}) and (v = ah) then . (m = rho v) . (m = rho text{ah}) . If (a = pi r^{2}), then . (m = rho pi r^{2}h) . Since both ( rho) and ( pi) are constants and (h) is negligible, ∴ (m propto r^{2}) . Since mass is directly proportional to radius squared, the graph could be linearized if (r^{2}) is plotted instead. . Precision and Uncertainty . The balanced used to measure the mass of the metal disks was accurate up to a hundredth of a gram, while the ruler used to measure the radius and height of the disks was accurate up to 1 millimeter (0.1 cm). As such, the radius was measured to the nearest hundredth of a centimeter or a tenth of a millimeter. . | Data Tables . m = mass . r = radii . H = height . Mass in Grams, Radius and height in cm, and Radius Squared of Each Metal Disk . Disk m (g) h (cm) r (cm)   r^2 (cm^2) . 1 | 0.07 | 0.0025 | 2.30 |   | 5.29 | . 2 | 0.14 | 0.0025 | 3.00 |   | 9.0 | . 3 | 0.25 | 0.0025 | 4.30 |   | 18.49 | . 4 | 0.37 | 0.0025 | 4.90 |   | 24.01 | . 5 | 0.73 | 0.0025 | 7.10 |   | 50.41 | . Graph of Non-Linearized Data: . . Equation: (y = 0.0133921x^{2} + 0.112825x - 0.0238674) . R2 : (0.9967) . This graph has non-linear data as it’s represented by a quadratic model. . Graph of Linearized Data: . . Line of the best fit equation: (y = 0.0145569x - 0.000100527) . r = (0.9983) . r2 = (0.9966 ) . This graph has linear data as it’s represented by a linear model. . Analysis Questions: . 1) What is the independent variable in your y = mx +b formula? . Considering the mathematic relationship between disk radius r and disk mass m, the independent variable from my line of best fit represents the radius of the disk squared. . 2) What does the slope represent in your y = mx +b formula? Show dimensionally that indeed that is what your slope represents and that the formula is valid dimensionally. . Using the (m = rho v) equation and the volume relationship, we can express the disk’s mass in terms of the radius and the height in this relationship: (m = rho pi r^{2}h). Since density (( rho)) and ( pi) are constants, and height ((h)) is negligible, we can essentially group these 3 constants into one value serving as the coefficient to the radius squared term. Thus, the slope is the product of the density, height, and ( pi). Since height has its units expressed in cm, density has units expressed in g/cm³, and ( pi) is a constant wth no units, the slope is a combination of all 3 constants and has units of g/cm2. . Because our slope has units of g/cm2, and x represents the radius squared expressed by cm2, and since our desired output ((y)) is mass in grams (g), the y-intercept ((b)) must have a unit of grams (g) in order for both sides of the equation to have the same units (grams). . (g = frac{g}{cm^{2}} cdot cm^{2} + g) . (g = g + g) . (g = g) . 3) Should the “b” in your y = mx + b formula be zero? Explain your answer. . The y-intercept ((b)) in my (y = mx + b) formula shouldn’t be zero unless the data naturally generates a line of best fit that passes through the origin. Forcing the y-intercept to pass through the origin would either alter the slope ((m)) or remove the y-intercept completely. This would result in an inaccurate interpretation of the model as the line is no longer set evenly between the data points. Thus we cannot guarantee the model’s integrity for future data points, rendering our model useless. . 4) Measure/estimate the “thickness” of your cylinders. Use that value to find the experimental density of your cylinders. Find a percent difference between your found density and the actual density. The actual material is aluminum. . (y = 0.0145569x - 0.000100527) . (slope = pi rho h) . ( rho = density) . ( rho = frac{ text{slope}}{h pi} = frac{0.0145569 frac{g}{cm^{2}}}{ pi(0.0025cm)} = 1.85 frac{g}{cm^{3}}) . The density of the metal disks according to my linear model is (1.85 frac{g}{cm^{3}}) , Since the metal used in the disk is Aluminum (density = (2.70 frac{g}{cm^{3}})) we can use the following calculations to determine our percent error . ( % Error = left | frac{Actual - Expected}{ text{Expected}} right | *100 % ) | . ( % Error = left | frac{1.85 frac{g}{cm^{3}} - 2.70 frac{g}{cm^{3}}}{2.70 frac{g}{cm^{3}}} right | *100 % = 31.5 % ) | . ∴ Percent difference = 31.5% . 5) Errors. Make sure you explain why your number is bigger or smaller than (if positive or negative difference.) . The number that I obtained is smaller than the actual value (31.5% error) because the instruments that we used to measure the disks’ dimensions had inaccuracies. The ruler that we used to measure the disks’ radius is only precise up to millimeters, and the balanced used to measure mass is only accurate up to the hundredth’s place, while actual instruments used to measure the actual value are much more precise. Additionally, the method I used to measure the height of the disks also had inherent inaccuracies, as folding the aluminum disks over each other may create tiny air pockets that add additional magnitude to my measured height, resulting in an inaccurate height measurement. The uncertainty of the ruler and also the inaccurate way of measuring height may have contributed to a greater height value than the actual value, resulting in a lower density value when I divided. Lastly, the disks weren’t in a perfectly circular shape, thus the direction that I measured the disk in might also have affected the end result, as measuring in different directions would produce different radii. . Synthesis Questions: . 1) In this experiment, if we had used disks with a greater thickness, would the slope of your best fit line have been different? Would your experimental value for density be the same? Explain. . Since slope represents the product of thickness, ( pi), and density, having a greater measured thickness would result in a much larger slope value. However, our experimental value of density would still be around the same, as an increase in thickness would also result in a proportionally large increase in mass, which will offset the thickness increase. . 2. How would your graph of m versus r2 be different if you had used disks of the same . thickness but made out of steel? Draw a second line on your m versus r2 plot that . represents disks made of steel. . The graph would be of m versus r2 would be different in that the slope of the graph would be much greater, this is because steel has a much higher density of (7.85 frac{g}{cm^{3}}) compared to aluminum’s (2.7 frac{g}{cm^{3}}) . . (Note: The blue line is a rough sketch of what the line of best fit would look like on the same scale as the aluminum graph is steel was used instead. This is not an accurate representation, just an approximation) . 3. Another group of students has acquired data for the exact same experiment; however, their disks are made of an unknown material that they are trying to determine. The group’s m versus r2 data produced a line of best fit with slope equal to 122 kg/m2. Each disk they measured had the same 0.5 cm thickness. Calculate the density of the unknown material and use the table below to help determine what material their disks are made of. . Work: . (Slope = 122kg/m^{2} , h = 0.5cm, slope = rho pi h) . (slope = 122 frac{ text{kg}}{m^{2}}( frac{1000g}{1kg})( frac{1m}{100cm})^{2} = 12.2 frac{g}{cm^{2}} = rho pi h) . ( rho = frac{ text{slope}}{ pi h} = frac{12.2 frac{g}{cm^{2}}}{ pi*0.5cm} = 7.77 frac{g}{cm^{3}}) . The closet material to a density of (7.77 frac{g}{cm^{3}}) is iron, which has a density of (7.8 frac{g}{cm^{3}}). The disks are most likely made out of iron. . Multiple Choice Questions: . 1. You perform the same experiment, but this time you plot a linear relationship between mass and the circumference of the disks rather than the radius. What is the slope of the linear plot? . Work: . (slope = rho pi h) . (m = rho v = rho pi r^{2}h) . (v = pi r^{2}h) . Let (c) be circumference . (c = 2 pi r) . (c^{2} = 4 pi^{2}r^{2}) . (r^{2} = frac{c^{2}}{4 pi^{2}}) . (m = rho pi h( frac{c^{2}}{4 pi^{2}}) = frac{ rho hc^{2}}{4 pi} = ( frac{ rho h}{4 pi})c^{2}) . () . Since ( rho) (density), h (height), and (4 pi) are all constants, these 3 values could be combined to form the slope for the linear plot, which is (( frac{ text{ph}}{4 pi})), Hence, E is the correct answer choice. . 2. Skipped . 3. Consider an experiment in which a student measures the mass and diameter of 10 . different-sized spheres, all made of the same material of uniform density ρ. For this . student to create a linear graph relating the mass of the sphere to its radius r, the . student would need to plot mass m versus which quantity: . ( text{let v be the volume of a sphere}) . (v = frac{4}{3} pi r^{3}) . (m = pv = ( frac{4p pi}{3})r^{3}) . Since (( frac{4p pi}{3})) is a constant, the student must plot a linear graph relating m versus the quality of radius cubed. Hence, option C is correct. .",
            "url": "https://ylu-1258.github.io/YLu-Blog/2022/08/28/Alex-Lu-Lab-1_-Measurements-and-Graphical-Analysis.html",
            "relUrl": "/2022/08/28/Alex-Lu-Lab-1_-Measurements-and-Graphical-Analysis.html",
            "date": " • Aug 28, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Installation Checks for Alex Lu",
            "content": "Defining color vars . RED=&#39; 033[0;31m&#39; GREEN=&#39; 033[0;32m&#39; BLUE=&#39; 033[0;34m&#39; MAGENTA=&#39; 033[0;35m&#39; CYAN=&#39; 033[0;36m&#39; NC=&#39; 033[0;0m&#39; . Checking for python installation . function CheckPythonInstall() { echo -e &quot;${BLUE}Checking python version${NC}&quot; if [[ $(python --version) ]]; then pyversion=$(python --version | cut -d&quot; &quot; -f2) echo -e &quot;${GREEN} - Python version ${MAGENTA}$pyversion${GREEN} has been installed! ${NC}&quot; else echo -e &quot;${RED} - Python not found ${NC}&quot; fi } CheckPythonInstall #python --version #python3 --version . Checking python version - Python version 3.9.12 has been installed! . Checking for Java intsallation . function CheckJavaInstall() { echo -e &quot;${CYAN}Checking java version${NC}&quot; if [[ $(java --version) ]]; then javaversion=$(java --version | head -n 1 | cut -d&quot; &quot; -f2) echo -e &quot;${GREEN} - Java version ${MAGENTA}$javaversion${GREEN} has been installed! ${NC}&quot; else echo -e &quot;${RED} - Java not found ${NC}&quot; fi } function CheckJavaCInstall() { echo -e &quot;${CYAN}Checking java compiler version${NC}&quot; if [[ $(javac --version) ]]; then javacversion=$(javac --version | head -n 1 | cut -d&quot; &quot; -f2) echo -e &quot;${GREEN} - JavaC version ${MAGENTA}$javacversion${GREEN} has been installed! ${NC}&quot; else echo -e &quot;${RED} - JavaC not found ${NC}&quot; fi } CheckJavaInstall CheckJavaCInstall . Checking java version - Java version 11.0.16 has been installed! Checking java compiler version - JavaC version 11.0.16 has been installed! . Checking For Anaconda installation . function CheckJupyterInstall() { echo -e &quot;${CYAN}Checking anaconda version${NC}&quot; if [[ $(conda --version) ]]; then condaversion=$(conda --version | cut -d&quot; &quot; -f2) echo -e &quot;${GREEN} - Anaconda version ${MAGENTA}$condaversion${GREEN} has been installed! ${NC}&quot; else echo -e &quot;${RED} - Anaconda not found ${NC}&quot; fi } CheckJupyterInstall . Checking jupyter version - Anaconda version 4.13.0 has been installed! . Checking for Jupyter package installation . function CheckCondaPackageInstall() { echo -e &quot;${CYAN}Checking jupyter package version${NC}&quot; if [[ $(conda list | grep $1) ]]; then packageversion=$(conda list | grep $1 | awk &#39;{print $2}&#39;) echo -e &quot;${GREEN} - Conda pacakge ${MAGENTA}$1${GREEN} version ${MAGENTA}$packageversion${GREEN} has been installed! ${NC}&quot; else echo -e &quot;${RED} - Conda package $1 not found ${NC}&quot; fi } CheckCondaPackageInstall &quot;nodejs&quot; . Checking jupyter package version - Conda pacakge nodejs version 6.11.2 has been installed! . Checking installed Jupyter kernels . function CheckJupyterKernelInstall() { echo -e &quot;${CYAN}Checking jupyter ${MAGENTA}$1${CYAN} kernel installation${NC}&quot; if [[ $(jupyter kernelspec list | grep $1) ]]; then kernelpath=$(jupyter kernelspec list | grep $1 | awk &#39;{print $2}&#39;) echo -e &quot;${GREEN} - Jupyter ${MAGENTA}$1${GREEN} kernel has been found at ${MAGENTA}$kernelpath${NC}&quot; else echo -e &quot;${RED} - Jupyter ${MAGENTA}$1${GREEN} kernel not found ${NC}&quot; fi } kernels=&quot;bash javascript python3&quot; for i in $kernels; do CheckJupyterKernelInstall $i done . Checking jupyter bash kernel installation - Jupyter bash kernel has been found at /home/eris29/.local/share/jupyter/kernels/bash Checking jupyter javascript kernel installation - Jupyter javascript kernel has been found at /home/eris29/.local/share/jupyter/kernels/javascript Checking jupyter python3 kernel installation - Jupyter python3 kernel has been found at /home/eris29/.local/share/jupyter/kernels/python3 .",
            "url": "https://ylu-1258.github.io/YLu-Blog/bash_checks",
            "relUrl": "/bash_checks",
            "date": " • Aug 26, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Intro to Pandas",
            "content": "Pandas . I will use a dataset of Fortune 1000 from Kaggle datasets to explore pandas library here. . The Fortune 1000 dataset is from the Fortune website. It contains U.S. company data for the year 2021. The dataset is 1000 rows and 18 columns. . Features: . Company - values are the name of the company Rank - The 2021 rank established by Fortune (1-1000) | Rank Change - The change in the rank from 2020 to 2021. There is only a rank change listed if the company is currently in the top 500 and was previously in the top 500. | Revenue - Revenue of each company in millions. This is the criteria used to rank each company. | Profit - Profit of each company in millions. Num. of Employees - The number of employees each company employs. | Sector - The sector of the market the company operates in. | City - The city where the company&#39;s headquarters is located. | State - The state where the company&#39;s headquarters is located | Newcomer - Indicates whether or not the company is new to the top Fortune 500 (&quot;yes&quot; or &quot;no&quot;). No value will be listed for companies outside of the top 500. | CEO Founder - Indicates whether the CEO of the company is also the founder (&quot;yes&quot; or &quot;no&quot;). | CEO Woman - Indicates whether the CEO of the company is a woman (&quot;yes&quot; or &quot;no&quot;). | Profitable - Indicates whether the company is profitable or not (&quot;yes&quot; or &quot;no&quot;). | Prev. Rank - The 2020 rank of the company, as established by Fortune. There will only be previous rank data for the top 500 companies. | CEO - The name of the CEO of the company | Website - The url of the company website | Ticker - The stock ticker symbol of public companies. Some rows will have empty values because the company is a private corporation. | Market Cap - The market cap (or value) of the company in millions. Some rows will have empty values because the company is private. Market valuations were determined on January 20, 2021. | . !wget -nc /content/ https://datasets21.s3-us-west-1.amazonaws.com/Fortune_1000.csv . /content/: Scheme missing. --2022-05-28 20:30:03-- https://datasets21.s3-us-west-1.amazonaws.com/Fortune_1000.csv Resolving datasets21.s3-us-west-1.amazonaws.com (datasets21.s3-us-west-1.amazonaws.com)... 52.219.192.90 Connecting to datasets21.s3-us-west-1.amazonaws.com (datasets21.s3-us-west-1.amazonaws.com)|52.219.192.90|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 138487 (135K) [text/csv] Saving to: ‘Fortune_1000.csv’ Fortune_1000.csv 100%[===================&gt;] 135.24K --.-KB/s in 0.07s 2022-05-28 20:30:03 (2.02 MB/s) - ‘Fortune_1000.csv’ saved [138487/138487] FINISHED --2022-05-28 20:30:03-- Total wall clock time: 0.3s Downloaded: 1 files, 135K in 0.07s (2.02 MB/s) . import pandas as pd f1000 = pd.read_csv(&#39;Fortune_1000.csv&#39;,index_col=0) . f1000.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Index: 1000 entries, Walmart to Liberty Oilfield Services Data columns (total 17 columns): # Column Non-Null Count Dtype -- -- 0 rank 1000 non-null int64 1 rank_change 1000 non-null float64 2 revenue 1000 non-null float64 3 profit 998 non-null float64 4 num. of employees 1000 non-null int64 5 sector 1000 non-null object 6 city 1000 non-null object 7 state 1000 non-null object 8 newcomer 500 non-null object 9 ceo_founder 1000 non-null object 10 ceo_woman 1000 non-null object 11 profitable 1000 non-null object 12 prev_rank 1000 non-null object 13 CEO 992 non-null object 14 Website 1000 non-null object 15 Ticker 938 non-null object 16 Market Cap 960 non-null object dtypes: float64(3), int64(2), object(12) memory usage: 140.6+ KB . f1000.head(3) . rank rank_change revenue profit num. of employees sector city state newcomer ceo_founder ceo_woman profitable prev_rank CEO Website Ticker Market Cap . company . Walmart 1 | 0.0 | 523964.0 | 14881.0 | 2200000 | Retailing | Bentonville | AR | no | no | no | yes | 1.0 | C. Douglas McMillon | https://www.stock.walmart.com | WMT | 411690 | . Amazon 2 | 3.0 | 280522.0 | 11588.0 | 798000 | Retailing | Seattle | WA | no | yes | no | yes | 5.0 | Jeffrey P. Bezos | https://www.amazon.com | AMZN | 1637405 | . Exxon Mobil 3 | -1.0 | 264938.0 | 14340.0 | 74900 | Energy | Irving | TX | no | no | no | yes | 2.0 | Darren W. Woods | https://www.exxonmobil.com | XOM | 177923 | . Select data using those labels . Because the axes in pandas have labels, I can select data using those labels — unlike in NumPy, where I needed to know the exact index location. To do this, I can use the DataFrame.loc[] attribute. The syntax for DataFrame.loc[] is: . df.loc[row_label, column_label] . Select Single Column . companies = f1000.loc[:,&#39;company&#39;] print(companies) print(type(f1000)) print(type(companies)) . Series object . print(f1000.loc[:,&#39;revenue&#39;]) print(f1000.loc[&#39;Apple&#39;,&#39;revenue&#39;]) . Select multiple columns . List of columns | Slice of columns | . f1000[[&#39;rank&#39;,&#39;revenue&#39;]] #f1000.loc[:,&#39;rank&#39;:&#39;sector&#39;] . Select rows by labels . f1000.loc[[&#39;Amazon&#39;, &#39;Apple&#39;]] #f1000.loc[&#39;Amazon&#39;:&#39;Apple&#39;] . Series.value_counts() method . Series.value_counts() method. This method displays each unique non-null value in a column and their counts in order. . sector_value_counts = f1000[&#39;sector&#39;].value_counts(ascending=True) print(sector_value_counts) . f1000[&#39;sector&#39;].value_counts().loc[&#39;Technology&#39;] . #f1000[&#39;rank_change&#39;].max() #f1000[&#39;rank_change&#39;].min() f1000[&#39;rank_change&#39;].describe() . f1000[&#39;rank_change&#39;].value_counts() . 0.0 544 -1.0 22 -2.0 18 2.0 16 4.0 15 ... 59.0 1 91.0 1 -30.0 1 28.0 1 98.0 1 Name: rank_change, Length: 118, dtype: int64 . Exercise: . List out the numbers of companies in the Fortune 1000 of the top 3 states . top_3_states = f1000[&#39;state&#39;].value_counts().head(3) print(top_3_states) . CA 121 TX 95 NY 89 Name: state, dtype: int64 . Exercise: . find the company that employs the most people in California in the dataset. . I can use the DataFrame.sort_values() method to sort the rows on the employees column . f1000[f1000[&#39;state&#39;]==&#39;CA&#39;].sort_values(&#39;num. of employees&#39;,ascending=False).head(1) . rank rank_change revenue profit num. of employees sector city state newcomer ceo_founder ceo_woman profitable prev_rank CEO Website Ticker Market Cap . company . Wells Fargo 30 | -1.0 | 103915.0 | 19549.0 | 259800 | Financials | San Francisco | CA | no | no | no | yes | 29.0 | Charles W. Scharf | https://www.wellsfargo.com | WFC | 99941 | . Exercise: . find the unique list of states in the dataset . To identify the unique states, I can use the Series.unique() method. This method returns an array of unique values from any series. . states = f1000[&#39;state&#39;].unique() print(states) . [&#39;AR&#39; &#39;WA&#39; &#39;TX&#39; &#39;CA&#39; &#39;RI&#39; &#39;NE&#39; &#39;MN&#39; &#39;PA&#39; &#39;MI&#39; &#39;CT&#39; &#39;OH&#39; &#39;NY&#39; &#39;IL&#39; &#39;DC&#39; &#39;NC&#39; &#39;GA&#39; &#39;IN&#39; &#39;MA&#39; &#39;NJ&#39; &#39;VA&#39; &#39;MO&#39; &#39;TN&#39; &#39;KY&#39; &#39;ID&#39; &#39;MD&#39; &#39;OR&#39; &#39;FL&#39; &#39;WI&#39; &#39;CO&#39; &#39;OK&#39; &#39;LA&#39; &#39;DE&#39; &#39;AZ&#39; &#39;IA&#39; &#39;NV&#39; &#39;KS&#39; &#39;AL&#39; &#39;SC&#39; &#39;ND&#39; &#39;NH&#39; &#39;MS&#39; &#39;PR&#39; &#39;UT&#39; &#39;HI&#39; &#39;VT&#39; &#39;ME&#39;] . Practice: . I&#39;m going to produce the following dictionary of the top employer in each state: . create an empty dictionary, top_employer_by_state to store the results of the exercise. . | Use the Series.unique() method to create an array of unique values from the state column . | Use a for loop to iterate over the array unique states. In each iteration: . | Select only the rows that have a state name equal to the current iteration. | Use DataFrame.sort_values() to sort those rows by the num. of employees column in descending order. | Select the first row from the sorted dataframe and convert the Dataframe into a series using DataFrame.squeeze() | Extract the company name from the index label company by Series.name. | Assign the results to the top_employer_by_state dictionary, using the state name as the key, and the company name as the value. | . top_exmployer_by_state = {} states = f1000[&#39;state&#39;].unique() for state in states: selected_companies = f1000[f1000[&#39;state&#39;]==state] top_exmployer_by_state[state] = selected_companies.sort_values(&#39;num. of employees&#39;, ascending=False).head(1).squeeze().name . for key in top_exmployer_by_state: print(key, &#39; : &#39;, top_exmployer_by_state[key]) . AR : Walmart WA : Amazon TX : Yum China Holdings CA : Wells Fargo RI : CVS Health NE : Berkshire Hathaway MN : Target PA : Aramark MI : Ford Motor CT : XPO Logistics OH : Kroger NY : IBM IL : Walgreens Boots Alliance DC : Danaher NC : Lowe&amp;#8217;s GA : Home Depot IN : Anthem MA : TJX NJ : Cognizant Technology Solutions VA : Hilton Worldwide Holdings MO : Emerson Electric TN : FedEx KY : Humana ID : Albertsons MD : Marriott International OR : Nike FL : Publix Super Markets WI : Kohl&amp;#8217;s CO : VF OK : Helmerich &amp; Payne LA : Lumen Technologies DE : DuPont AZ : Republic Services IA : Casey&amp;#8217;s General Stores NV : MGM Resorts International KS : Yellow AL : Encompass Health SC : Sonoco Products ND : MDU Resources Group NH : PC Connection MS : Sanderson Farms PR : Popular UT : Nu Skin Enterprises HI : Hawaiian Holdings VT : NLV Financial ME : IDEXX Laboratories . Reference . pandas API reference . pandas vs. NumPy .",
            "url": "https://ylu-1258.github.io/YLu-Blog/jupyter/interests/2022/08/25/Pandas-for-Beginners.html",
            "relUrl": "/jupyter/interests/2022/08/25/Pandas-for-Beginners.html",
            "date": " • Aug 25, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "08/25/2022 Lecture",
            "content": "Lecture - 08/25/2022 . To build up a relationshhip with my partner, I should comment in his blog and also open up review tickets to communicate with him . When working with others, always pull before you make any additions, this ensures that we are on the latest version and that there are no difference conflicts. . There are multiple “shells” installed on a linux machine, such as bash, dash and zsh. The commands that we enter into terminal are like a pseudo-language. We can create bash scripts to automate actions in terminal for us. . Bash - Analyzing part 1 . cd $project #cd means &quot;Change Directory&quot;, $project is a variable named project ls # lists directory ls -a # lists directory with hidden files ls -al # lists directory with hidden files in long format . By using bash we can easily create scripts that automate terminal operations for us. . The Cloud . The cloud contains all git repositories. Individual computers can clone repositories from the cloud and down to our own SSD. This creates a link between our local repository and the remote repository. . A pull action will pull any new updates made to the repository down to our local repository and update it with the latest changes. . A push action will push any new updates from our local repository up to our remote directory in the cloud and contribute to the git repository. .",
            "url": "https://ylu-1258.github.io/YLu-Blog/markdown/apcsp/2022/08/25/Lecture-Intro-Python.html",
            "relUrl": "/markdown/apcsp/2022/08/25/Lecture-Intro-Python.html",
            "date": " • Aug 25, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "Intro to Numpy",
            "content": "NumPy . NumPy is the fundamental package for scientific computing with Python. . At the core of the NumPy package, is the ndarray object or n-dimensional array. In programming, array describes a collection of elements, similar to a list. The word n-dimensional refers to the fact that ndarrays can have one or more dimensions. . Here I will directly convert a list to an ndarray using the numpy.array() constructor. To create a 1D ndarray, I can pass in a single list . import numpy as np #using the alias np array_data = np.array([1,2,3,4]) . print(array_data) print(type(array_data)) . [1 2 3 4] &lt;class &#39;numpy.ndarray&#39;&gt; . It&#39;s often useful to know the number of rows and columns in a ndarray. I can use the ndarray.shape attribute. . array_2D = np.array([[5, 10, 15], [20, 25, 30]]) print(array_2D.shape) . (2, 3) . Vectorization in NumPy . The NumPy library takes advantage of a processor feature called Single Instruction Multiple Data (SIMD) to process data faster. SIMD allows a processor to perform the same operation on multiple data points in a single processor cycle. . The concept of replacing for loops with operations applied to multiple data points at once is called vectorization, and ndarrays make vectorization possible. . numbers = [[6, 5], [1, 3], [5, 6], [1, 4], [3, 7], [5, 8], [3, 5], [8, 4]] print(*numbers, sep=&#39; n&#39;) . [6, 5] [1, 3] [5, 6] [1, 4] [3, 7] [5, 8] [3, 5] [8, 4] . sums = [] for row in numbers: row_sum = row[0] + row[1] sums.append(row_sum) print(sums) . [11, 4, 11, 5, 10, 13, 8, 12] . # Convert the list of lists to an ndarray np_numbers = np.array(numbers) sums = np_numbers[:,0] + np_numbers[:,1] print(sums) . [11 4 11 5 10 13 8 12] . When I selected each column, we used the syntax ndarray[:,c] where c is the column index I wanted to select. The colon selects all rows. . #print(np_numbers) #print(np_numbers[1]) #print(np_numbers[2:]) #print(np_numbers[3,1]) #print(np_numbers[:,1]) # Select specific row rows = [0, 2, 4] print(np_numbers[rows, :]) . [[6 5] [5 6] [3 7]] . Explore the numerical dataset . To explore two-dimensional (2D) ndarrays, I&#39;ll analyze New York City taxi trip data released by the city of New York. . !wget -nc /content/ https://datasets21.s3-us-west-1.amazonaws.com/nyc_taxis.csv . /content/: Scheme missing. File ‘nyc_taxis.csv’ already there; not retrieving. . !wget --help . GNU Wget 1.19.4, a non-interactive network retriever. Usage: wget [OPTION]... [URL]... Mandatory arguments to long options are mandatory for short options too. Startup: -V, --version display the version of Wget and exit -h, --help print this help -b, --background go to background after startup -e, --execute=COMMAND execute a `.wgetrc&#39;-style command Logging and input file: -o, --output-file=FILE log messages to FILE -a, --append-output=FILE append messages to FILE -d, --debug print lots of debugging information -q, --quiet quiet (no output) -v, --verbose be verbose (this is the default) -nv, --no-verbose turn off verboseness, without being quiet --report-speed=TYPE output bandwidth as TYPE. TYPE can be bits -i, --input-file=FILE download URLs found in local or external FILE -F, --force-html treat input file as HTML -B, --base=URL resolves HTML input-file links (-i -F) relative to URL --config=FILE specify config file to use --no-config do not read any config file --rejected-log=FILE log reasons for URL rejection to FILE Download: -t, --tries=NUMBER set number of retries to NUMBER (0 unlimits) --retry-connrefused retry even if connection is refused -O, --output-document=FILE write documents to FILE -nc, --no-clobber skip downloads that would download to existing files (overwriting them) --no-netrc don&#39;t try to obtain credentials from .netrc -c, --continue resume getting a partially-downloaded file --start-pos=OFFSET start downloading from zero-based position OFFSET --progress=TYPE select progress gauge type --show-progress display the progress bar in any verbosity mode -N, --timestamping don&#39;t re-retrieve files unless newer than local --no-if-modified-since don&#39;t use conditional if-modified-since get requests in timestamping mode --no-use-server-timestamps don&#39;t set the local file&#39;s timestamp by the one on the server -S, --server-response print server response --spider don&#39;t download anything -T, --timeout=SECONDS set all timeout values to SECONDS --dns-timeout=SECS set the DNS lookup timeout to SECS --connect-timeout=SECS set the connect timeout to SECS --read-timeout=SECS set the read timeout to SECS -w, --wait=SECONDS wait SECONDS between retrievals --waitretry=SECONDS wait 1..SECONDS between retries of a retrieval --random-wait wait from 0.5*WAIT...1.5*WAIT secs between retrievals --no-proxy explicitly turn off proxy -Q, --quota=NUMBER set retrieval quota to NUMBER --bind-address=ADDRESS bind to ADDRESS (hostname or IP) on local host --limit-rate=RATE limit download rate to RATE --no-dns-cache disable caching DNS lookups --restrict-file-names=OS restrict chars in file names to ones OS allows --ignore-case ignore case when matching files/directories -4, --inet4-only connect only to IPv4 addresses -6, --inet6-only connect only to IPv6 addresses --prefer-family=FAMILY connect first to addresses of specified family, one of IPv6, IPv4, or none --user=USER set both ftp and http user to USER --password=PASS set both ftp and http password to PASS --ask-password prompt for passwords --use-askpass=COMMAND specify credential handler for requesting username and password. If no COMMAND is specified the WGET_ASKPASS or the SSH_ASKPASS environment variable is used. --no-iri turn off IRI support --local-encoding=ENC use ENC as the local encoding for IRIs --remote-encoding=ENC use ENC as the default remote encoding --unlink remove file before clobber --xattr turn on storage of metadata in extended file attributes Directories: -nd, --no-directories don&#39;t create directories -x, --force-directories force creation of directories -nH, --no-host-directories don&#39;t create host directories --protocol-directories use protocol name in directories -P, --directory-prefix=PREFIX save files to PREFIX/.. --cut-dirs=NUMBER ignore NUMBER remote directory components HTTP options: --http-user=USER set http user to USER --http-password=PASS set http password to PASS --no-cache disallow server-cached data --default-page=NAME change the default page name (normally this is &#39;index.html&#39;.) -E, --adjust-extension save HTML/CSS documents with proper extensions --ignore-length ignore &#39;Content-Length&#39; header field --header=STRING insert STRING among the headers --max-redirect maximum redirections allowed per page --proxy-user=USER set USER as proxy username --proxy-password=PASS set PASS as proxy password --referer=URL include &#39;Referer: URL&#39; header in HTTP request --save-headers save the HTTP headers to file -U, --user-agent=AGENT identify as AGENT instead of Wget/VERSION --no-http-keep-alive disable HTTP keep-alive (persistent connections) --no-cookies don&#39;t use cookies --load-cookies=FILE load cookies from FILE before session --save-cookies=FILE save cookies to FILE after session --keep-session-cookies load and save session (non-permanent) cookies --post-data=STRING use the POST method; send STRING as the data --post-file=FILE use the POST method; send contents of FILE --method=HTTPMethod use method &#34;HTTPMethod&#34; in the request --body-data=STRING send STRING as data. --method MUST be set --body-file=FILE send contents of FILE. --method MUST be set --content-disposition honor the Content-Disposition header when choosing local file names (EXPERIMENTAL) --content-on-error output the received content on server errors --auth-no-challenge send Basic HTTP authentication information without first waiting for the server&#39;s challenge HTTPS (SSL/TLS) options: --secure-protocol=PR choose secure protocol, one of auto, SSLv2, SSLv3, TLSv1, TLSv1_1, TLSv1_2 and PFS --https-only only follow secure HTTPS links --no-check-certificate don&#39;t validate the server&#39;s certificate --certificate=FILE client certificate file --certificate-type=TYPE client certificate type, PEM or DER --private-key=FILE private key file --private-key-type=TYPE private key type, PEM or DER --ca-certificate=FILE file with the bundle of CAs --ca-directory=DIR directory where hash list of CAs is stored --crl-file=FILE file with bundle of CRLs --pinnedpubkey=FILE/HASHES Public key (PEM/DER) file, or any number of base64 encoded sha256 hashes preceded by &#39;sha256//&#39; and separated by &#39;;&#39;, to verify peer against --random-file=FILE file with random data for seeding the SSL PRNG HSTS options: --no-hsts disable HSTS --hsts-file path of HSTS database (will override default) FTP options: --ftp-user=USER set ftp user to USER --ftp-password=PASS set ftp password to PASS --no-remove-listing don&#39;t remove &#39;.listing&#39; files --no-glob turn off FTP file name globbing --no-passive-ftp disable the &#34;passive&#34; transfer mode --preserve-permissions preserve remote file permissions --retr-symlinks when recursing, get linked-to files (not dir) FTPS options: --ftps-implicit use implicit FTPS (default port is 990) --ftps-resume-ssl resume the SSL/TLS session started in the control connection when opening a data connection --ftps-clear-data-connection cipher the control channel only; all the data will be in plaintext --ftps-fallback-to-ftp fall back to FTP if FTPS is not supported in the target server WARC options: --warc-file=FILENAME save request/response data to a .warc.gz file --warc-header=STRING insert STRING into the warcinfo record --warc-max-size=NUMBER set maximum size of WARC files to NUMBER --warc-cdx write CDX index files --warc-dedup=FILENAME do not store records listed in this CDX file --no-warc-digests do not calculate SHA1 digests --no-warc-keep-log do not store the log file in a WARC record --warc-tempdir=DIRECTORY location for temporary files created by the WARC writer Recursive download: -r, --recursive specify recursive download -l, --level=NUMBER maximum recursion depth (inf or 0 for infinite) --delete-after delete files locally after downloading them -k, --convert-links make links in downloaded HTML or CSS point to local files --convert-file-only convert the file part of the URLs only (usually known as the basename) --backups=N before writing file X, rotate up to N backup files -K, --backup-converted before converting file X, back up as X.orig -m, --mirror shortcut for -N -r -l inf --no-remove-listing -p, --page-requisites get all images, etc. needed to display HTML page --strict-comments turn on strict (SGML) handling of HTML comments Recursive accept/reject: -A, --accept=LIST comma-separated list of accepted extensions -R, --reject=LIST comma-separated list of rejected extensions --accept-regex=REGEX regex matching accepted URLs --reject-regex=REGEX regex matching rejected URLs --regex-type=TYPE regex type (posix|pcre) -D, --domains=LIST comma-separated list of accepted domains --exclude-domains=LIST comma-separated list of rejected domains --follow-ftp follow FTP links from HTML documents --follow-tags=LIST comma-separated list of followed HTML tags --ignore-tags=LIST comma-separated list of ignored HTML tags -H, --span-hosts go to foreign hosts when recursive -L, --relative follow relative links only -I, --include-directories=LIST list of allowed directories --trust-server-names use the name specified by the redirection URL&#39;s last component -X, --exclude-directories=LIST list of excluded directories -np, --no-parent don&#39;t ascend to the parent directory Mail bug reports and suggestions to &lt;bug-wget@gnu.org&gt; . from csv import reader #Load data into the notebook with open(&#39;nyc_taxis.csv&#39;, &#39;r&#39;) as taxis_file: taxis = list(reader(taxis_file)) print(len(taxis)) print(len(taxis[0])) . 2014 15 . import numpy as np np_taxis = np.array(taxis) . print(np_taxis[:3]) np_taxis.shape . [[&#39;pickup_year&#39; &#39;pickup_month&#39; &#39;pickup_day&#39; &#39;pickup_dayofweek&#39; &#39;pickup_time&#39; &#39;pickup_location_code&#39; &#39;dropoff_location_code&#39; &#39;trip_distance&#39; &#39;trip_length&#39; &#39;fare_amount&#39; &#39;fees_amount&#39; &#39;tolls_amount&#39; &#39;tip_amount&#39; &#39;total_amount&#39; &#39;payment_type&#39;] [&#39;2016&#39; &#39;1&#39; &#39;1&#39; &#39;5&#39; &#39;0&#39; &#39;2&#39; &#39;4&#39; &#39;21.00&#39; &#39;2037&#39; &#39;52.00&#39; &#39;0.80&#39; &#39;5.54&#39; &#39;11.65&#39; &#39;69.99&#39; &#39;1&#39;] [&#39;2016&#39; &#39;1&#39; &#39;1&#39; &#39;5&#39; &#39;0&#39; &#39;2&#39; &#39;1&#39; &#39;16.29&#39; &#39;1520&#39; &#39;45.00&#39; &#39;1.30&#39; &#39;0.00&#39; &#39;8.00&#39; &#39;54.30&#39; &#39;1&#39;]] . (2014, 15) . I&#39;ll only work with a subset of the real data — approximately 90,000 yellow taxi trips to and from New York City airports between January and June 2016. This data set includes a 1/50th random sample. Below is information about selected columns from the dataset: . pickup_year: the year of the trip pickup_month: the month of the trip (January is 1, December is 12) | pickup_day: the day of the month of the trip | pickup_location_code: the airport or borough where the trip started | dropoff_location_code: the airport or borough where the trip ended | trip_distance: the distance of the trip in miles | trip_length: the length of the trip in seconds | fare_amount: the base fare of the trip, in dollars | total_amount: the total amount charged to the passenger, including all fees, tolls and tips | . Detailed information on all columns could be found here. . # Access the column by names np_taxis = np.genfromtxt(&#39;nyc_taxis.csv&#39;,delimiter=&#39;,&#39;, names= True) . References: . NumPy genfromtxt function - API Reference . Tutorial for genfromtxt . print(np_taxis.shape) print(np_taxis[10][&#39;pickup_location_code&#39;]) . z = np.array([1,2]) print(z.shape) . y = np.array([[1],[2]]) print(y.shape) . np_taxis = np.genfromtxt(&#39;nyc_taxis.csv&#39;,delimiter=&#39;,&#39;, skip_header=1) . print(np_taxis.shape) . print(np_taxis[10]) . np.set_printoptions(suppress=True) . print(np_taxis[10]) . print(np_taxis[1]) . cols = [5, 6, 9, 10] print(np_taxis[:,cols]) . Get the Frequency Table of taxis based on the Pickup Location . print(np.unique(np_taxis[:,6])) . unique, counts = np.unique(np_taxis[:,6], return_counts=True) print(unique) print(counts) . print(np_taxis[:,-2]) . # Calculate the mph of each trip trip_distance_miles = np_taxis[:,7] trip_length_seconds = np_taxis[:,8] trip_length_hours = trip_length_seconds / 3600 # 3600 seconds is one hour trip_mph = trip_distance_miles / trip_length_hours print(trip_mph) . total_amount = np_taxis[:,-2] # measures of central tendency mean = np.mean(total_amount) median = np.median(total_amount) # measures of dispersion min = np.amin(total_amount) max = np.amax(total_amount) range = np.ptp(total_amount) varience = np.var(total_amount) sd = np.std(total_amount) print(&quot;Descriptive analysis&quot;) print(&quot; n&quot;) print(&quot;Measures of Central Tendency&quot;) print(&quot;Mean =&quot;, mean) print(&quot;Median =&quot;, median) print(&quot;Measures of Dispersion&quot;) print(&quot;Minimum =&quot;, min) print(&quot;Maximum =&quot;, max) print(&quot;Range =&quot;, range) print(&quot;Varience =&quot;, varience) print(&quot;Standard Deviation =&quot;, sd) .",
            "url": "https://ylu-1258.github.io/YLu-Blog/jupyter/interests/2022/08/24/Numpy-for-Beginners.html",
            "relUrl": "/jupyter/interests/2022/08/24/Numpy-for-Beginners.html",
            "date": " • Aug 24, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "08/24/2022 Lecture",
            "content": "Lecture - 08/24/2022 . Using documents as blog posts . To import past assignemnts and documents from document-based editors such as word and google docs, we can import such files as .docx documents and place them under the _word subdirectory in our blog. . NOTE: Doing so does not keep the formatting of the document, any font colors, size, styling is not preserved, additionall work with CSS is required for original effects. . Blog Front-Matter . Each markdown or jupyter post contains a set configurations at the head of the file known as Front-Matter Front-matter settings are seperated into two main groups, keys, and values. . keys: The name of the configuration or setting we wish to edit value: The value or data we grant to a specific configuration . IMPORTANT: It is crucial to always pair a key with a value, a blank value on the key overwrites the default value, making the key take on a null value and breaking the front-matter To define front matter in markdown, use the following format toc: true layout: post description: APCSP Lecture 2 categories: [markdown, notes] title: 08/24/2022 Lecture author: Alex Lu show_tags: true hide: true comments: true ... . To define front-matter in computational notebooks, use the following format # Jupyter Notebook Demonstration &gt; My first Jupyter notebook on my blog! - toc: true - title: First Jupyter Notebook - author: Alex Lu - badges: true - comments: true - categories: [jupyter] . NOTE: A title and and description must be specified with the # and &gt; characters respectively, furthermore, each front-matter key and value should be prefixed with a hyphen (-) similar to a markdown list. . Adding pages on the navbar . If we ever find the need to add a special page on the top of our site in the navbar, simply move the post into the _pages directory, and change the front matter key layout from post to page . NOTE: setting a table of contents in the front-matter does not work for a page, further tinkering with html is required. . _config.yml . Most of the blog’s default keys and values are defined within the _config.yml configuration file in the base directory of the blog. The values under _config.yml are in the standard key: value syntax prevalent in most .yml files. NOTABLE KEYS: | Key | function | | - | - | | title | Title of site in upper left hand corner | | baseurl | The url path to the blog | | show_description | Display brief description of blog post uner blog lists | | show_image | Display image on post card | .",
            "url": "https://ylu-1258.github.io/YLu-Blog/markdown/apcsp/2022/08/24/Lecture-site-organization-and-configuration.html",
            "relUrl": "/markdown/apcsp/2022/08/24/Lecture-site-organization-and-configuration.html",
            "date": " • Aug 24, 2022"
        }
        
    
  
    
        ,"post8": {
            "title": "Python Quiz",
            "content": "Here is the code for my quiz . Colors really help to spruce things up a little, can you get 100% without looking at the code? . Example Playthrough: . import getpass class Colors: &#39;&#39;&#39; Colors class to print colored text to terminal, Does not work in fastpages :/ &#39;&#39;&#39; # Man I love ANSI PINK = &#39; 033[95m&#39; LILAC = &#39; 033[94m&#39; BLUE = &#39; 033[96m&#39; GREEN = &#39; 033[92m&#39; YELLOW = &#39; 033[93m&#39; RED = &#39; 033[91m&#39; ENDC = &#39; 033[0m&#39; BOLD = &#39; 033[1m&#39; UNDERLINE = &#39; 033[4m&#39; class Quiz(): # Main class for the quiz def __init__(self): # Quiz &quot;constructor&quot;, initiates list of questions and answers and other settings. self.ques = [] self.ans = [] self.colors = Colors() self.showans = False # Show correct answers after a wrong input self.total = 0 # Total questions self.correct = 0 # Total right self.skipped = 0 # Total skipped def addQues(self, question, answer): &#39;&#39;&#39; Adding Questions and answers to the quiz &#39;&#39;&#39; self.ques.append(question) self.ans.append(answer) self.total += 1 # increment total by 1 def askQues(self, idx): &#39;&#39;&#39; Helper function to ask one question, check answer, increment student data &#39;&#39;&#39; print(self.colors.PINK + &quot;QUESTION: &quot; + self.colors.ENDC + self.colors.BOLD + self.ques[idx] + self.colors.ENDC) # Print Question rsp = input(self.colors.YELLOW + &quot;What is your response? &quot; + self.colors.ENDC) # Get Response if rsp.lower() == self.ans[idx].lower(): # Check answer print(self.colors.GREEN + &quot;YOU ARE CORRECT!&quot; + self.colors.ENDC + &quot; Response &quot; + self.colors.BLUE + rsp + self.colors.ENDC + &quot; is correct!&quot;) self.correct += 1 elif rsp.lower() == &quot;/s&quot;: if self.showans: print(self.colors.YELLOW + &quot;Skipping....&quot; + &quot; The right answer was &quot; + self.colors.BLUE + self.ans[idx] + self.colors.ENDC) else: rint(self.colors.YELLOW + &quot;Skipping....&quot; + self.colors.ENDC) self.skipped += 1 else: if self.showans: print(self.colors.RED + &quot;Response &#39;&quot; + rsp + &quot;&#39; is incorrect.&quot; + self.colors.ENDC + &quot; The right answer was &quot; + self.colors.BLUE + self.ans[idx] + self.colors.ENDC) else: print(self.colors.RED + &quot;Response &#39;&quot; + rsp + &quot;&#39; is incorrect.&quot; + self.colors.ENDC) def percentage(self, x, y): &#39;&#39;&#39; Function to calculate percentage correct &#39;&#39;&#39; return 100 * float(x)/float(y) def playQuiz(self): &#39;&#39;&#39; Main Quiz loop, set settings and ask questions &#39;&#39;&#39; show_ans = input(self.colors.UNDERLINE + &quot;Would you like to show correct answers after incorrect responses? [y/n]&quot; + self.colors.ENDC + &quot; &quot;) print(self.colors.YELLOW + &quot;GOOD LUCK {0}!&quot;.format(getpass.getuser().upper()) + &quot; Type &#39;&quot; + self.colors.BLUE + &quot;/s&quot; + self.colors.YELLOW + &quot;&#39; to skip!&quot;) if show_ans in [&quot;y&quot;, &quot;yes&quot;, &quot;Y&quot;, &quot;YES&quot;]: # Multiple cases of user inputs, assume any other input / no input == False. self.showans = True for i in range(0,self.total): # Iterate over all questions, no repetitive code here self.askQues(i) # Print a little congratulations message print(self.colors.LILAC + &quot;Congratulations! you got &quot; + self.colors.GREEN + &#39;{0:.2f}&#39;.format(self.percentage(self.correct, self.total)) + &quot;%&quot; + self.colors.LILAC + &quot; and {0} questions skipped on this quiz!&quot;.format(self.colors.YELLOW + str(self.skipped) + self.colors.LILAC)) # Creating our quiz q1 = Quiz() # AYO CHEATER STOP LOOKIN HERE q1.addQues(&quot;Name the Python output command mentioned in this lesson?&quot;, &quot;print&quot;) q1.addQues(&quot;If you see many lines of code in order, what would College Board call it?&quot;, &quot;sequence&quot;) q1.addQues(&quot;What keyword in python is used to describe a function?&quot;, &quot;def&quot;) q1.addQues(&quot;What command is used to include other functions that were previously developed?&quot;, &quot;import&quot;) q1.addQues(&quot;What command is used to evaluate correct or incorrect response in this quiz?&quot;, &quot;if&quot;) q1.addQues(&quot;Each &#39;if&#39; command contains an &#39;_________&#39; to determine a true or false condition?&quot;, &quot;expression&quot;) q1.addQues(&quot;What is an input to a function or method called?&quot;, &quot;parameter&quot;) q1.addQues(&quot;If Input is data the computer receives, what is the data that the computer sends back?&quot;, &quot;output&quot;) q1.addQues(&quot;What is a reusable block of code called?&quot;, &quot;function&quot;) q1.addQues(&quot;What operator is used for string concatenation in Python?&quot;, &quot;+&quot;) q1.playQuiz() . GOOD LUCK ERIS29! Type &#39;/s&#39; to skip! QUESTION: Name the Python output command mentioned in this lesson? YOU ARE CORRECT! Response print is correct! QUESTION: If you see many lines of code in order, what would College Board call it? YOU ARE CORRECT! Response sequence is correct! QUESTION: What keyword in python is used to describe a function? YOU ARE CORRECT! Response def is correct! QUESTION: What command is used to include other functions that were previously developed? Response &#39;include&#39; is incorrect. The right answer was import QUESTION: What command is used to evaluate correct or incorrect response in this quiz? YOU ARE CORRECT! Response if is correct! QUESTION: Each &#39;if&#39; command contains an &#39;_________&#39; to determine a true or false condition? Skipping.... The right answer was expression QUESTION: What is an input to a function or method called? YOU ARE CORRECT! Response parameter is correct! QUESTION: If Input is data the computer receives, what is the data that the computer sends back? YOU ARE CORRECT! Response output is correct! QUESTION: What is a reusable block of code called? YOU ARE CORRECT! Response function is correct! QUESTION: What operator is used for string concatenation in Python? YOU ARE CORRECT! Response + is correct! Congratulations! you got 80.00% and 1 questions skipped on this quiz! .",
            "url": "https://ylu-1258.github.io/YLu-Blog/jupyter/2022/08/23/alex-quiz.html",
            "relUrl": "/jupyter/2022/08/23/alex-quiz.html",
            "date": " • Aug 23, 2022"
        }
        
    
  
    
        ,"post9": {
            "title": "Stein EC precis",
            "content": "Alex Lu Mrs. DaFoe APEL, Period 5 21 August, 2022 . The Hypocritical Truth of American Education . In his op-ed, “We’re teaching kids to follow their dreams. Maybe teach them to be helpful instead”, Joel Stein asserts that the American education system is hypocritical in its attempts to teach young Americans about stories of helping others, but never teach them the necessary skills to help others. To prove the sanctimoniousness of our education system, Stein begins with a personal anecdote from his elementary school days, a time where teachers struggled to teach their self-absorbed students about important historical figures. Joel then uses this anecdote in order to introduce his main point of criticism: The so-called “living wax museums” used by teachers today to dress up their students as heroic people allows the students to perform speeches in front of their classmates, giving them a taste of leadership through the lens of a past American hero. While this may sound good on paper, Stein provides yet another anecdote in paragraph 2, this time in the classroom of his 4th-grade son instead, wryly reminiscing the ironic atmosphere of the room一 opposite of what one would expect from an empowering speech. For example, he compares the classroom to a standup comedy show, where “each comedian has to drag in two audience members to fill the house.” Stein continues to scoff at the lunacy of the situation by recalling his son’s preposterous stories about JFK being a sailor and discovering “14 bags of Whoppahs and a Mahs bah.” Through the usage of such personal experiences, Stein develops pathos that appeals to the audience on the failures of our educational system to deliver the very values it must prioritize: knowledge, character, and education. It is essential that Stein appeals to his audience in this way so as to emotionally stir other teachers and parents in his audience to realize the fundamental issues in our schools and the lack of action to amend such ailments in society. Besides anecdotes and pathos, Stein uses exaggeration and satire to convey the ironic state of things. In paragraph 5, Stein openly reveals that each student concluded their speeches with the good qualities of their model and not with the impact or morals behind their actions. Due to this, Stein jokingly states that Malala Yousafzai, a Pakistani activist for female education, would “rescind the right of girls to go to this school” if she were ever to witness these children focusing on her “pursuing her dreams” and not her altruistic actions. Using Malala’s status as a child activist, Stein generates a satirical effect and humorously addresses the misrepresentation of these significant figures by clueless young children and the naive pedagogy constructed by the teachers who organize these events. Stein uses this same example to address how schools have drifted from teaching children to be helpful to others and instead molding them into potential leaders. Finally, he addresses such schools’ hypocrisy once again as they aim to teach students how to become good leaders but quickly turn critical if their students want to become the next “Nixon or Trump”. Through his anecdotes and satire, Stein humorously criticizes the hypocrisy of American schools while maintaining a serious attitude towards the end in an attempt to educate fellow parents and teachers on this crisis. .",
            "url": "https://ylu-1258.github.io/YLu-Blog/markdown/apel/2022/08/21/APEL-Stein-Precis.html",
            "relUrl": "/markdown/apel/2022/08/21/APEL-Stein-Precis.html",
            "date": " • Aug 21, 2022"
        }
        
    
  
    
        ,"post10": {
            "title": "First Jupyter Notebook",
            "content": "Let&#39;s Print Something! . Allow me to demonstrate the print() function in python! . var = &quot;World!&quot; print(&quot;Hello &quot; + var) . Hello World! . Let&#39;s Print some more! . Loops are really fun sometimes, let&#39;s say it a couple more times 🔁 . for i in range(5): print(&quot;Hello &quot; + var) . Hello World! Hello World! Hello World! Hello World! Hello World! . Have a Bogosort algorithm! . The real question is what time complexity this algorithm has 🤔 . from random import shuffle as sh def sorted(arr): length = len(arr) for i in range(0, length-1): if (arr[i] &gt; arr[i+1] ): return False return True def shuffle(arr): sh(arr) def Bogosort(arr): while not sorted(arr): shuffle(arr) return arr array = [23,10,49,9] print(Bogosort(array)) . [9, 10, 23, 49] .",
            "url": "https://ylu-1258.github.io/YLu-Blog/jupyter/2022/08/20/example-post.html",
            "relUrl": "/jupyter/2022/08/20/example-post.html",
            "date": " • Aug 20, 2022"
        }
        
    
  
    
        ,"post11": {
            "title": "Hello World!",
            "content": "Hello World! 🌎 . This is my first blog post! I’m Alex Lu, and I’m excited to learn more about how to build and develop my blog. . Have some code! 💻 . Ayo is that a recursive function? . def fibo(n): if n == 1: return 0 if n == 2: return 1 return fibo(n-1) + fibo(n-2) print(fibo(10)) # prints 34 . That was sick! . Thanks for visiting 🥳 . Have a cookie 🍪 .",
            "url": "https://ylu-1258.github.io/YLu-Blog/markdown/2022/08/19/hello-world.html",
            "relUrl": "/markdown/2022/08/19/hello-world.html",
            "date": " • Aug 19, 2022"
        }
        
    
  
    
        ,"post12": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://ylu-1258.github.io/YLu-Blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post13": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://ylu-1258.github.io/YLu-Blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  

  
      ,"page2": {
          "title": "Vocab",
          "content": "Vocab . The Vocab should be oriented in this fashion . Vocab | Definition | Example | . Week 0 Vocab . Vocab Definition Example . Output | Data that is returned by the computer to the user | print(“Hello world!”) | . Input | Data that is taken in by the computer from the user | input(“What is your age”) | .",
          "url": "https://ylu-1258.github.io/YLu-Blog/vocab/",
          "relUrl": "/vocab/",
          "date": ""
      }
      
  

  
      ,"page3": {
          "title": "Lecture Notes",
          "content": "What is this page? . This page contains all of the notes I’ve taken during Mr. Mortensen’s lectures, this might be useful while I’m trouble shooting my blog or other bugs in my code. If you’re another APCSP student, feel free to use this page to further your knowledge or review any points you missed in class! . Lectures TOC . Date Link and subject . 08 - 25 - 2022 | Bash and Cloud Lecture | . 08 - 24 - 2022 | Blog posting and configuration Lecture | .",
          "url": "https://ylu-1258.github.io/YLu-Blog/notes/",
          "relUrl": "/notes/",
          "date": ""
      }
      
  

  
      ,"page4": {
          "title": "About Me",
          "content": "Hello There! . My name is Alex Lu and if you want to reach out to me about anything, you can contact me through the methods below! . Discord: Eris29#2693 🎮 | Email: maodou1258@gmail.com 📧 | Phone: (858)-688-4567 📱 | . About Me 📓: . I am currently a Junior at Del Norte High School taking the APCSP course, I hope to major in computer science in the future and also pursue it as a prospective carreer path in the future . My Hobbies 🎾 . I have many hobbies that I do to pass my time, here are just a few of them: . Reading | Programming | Playing tennis | Playing video games | Watching youtube videos | And many more! | . My Interests 🔬: . I am interested in anything related to computers, I am currently working on various projects centered around: . Machine Learning 🤖 | Image processing 🖼️ | Webscraping 🌐 | Cyber Security 🐱‍💻 | .",
          "url": "https://ylu-1258.github.io/YLu-Blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  

  
  

  
  

  
  

  
  

  
  

  
      ,"page12": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://ylu-1258.github.io/YLu-Blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}